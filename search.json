[
  {
    "objectID": "NBA Project/project.html",
    "href": "NBA Project/project.html",
    "title": "Jake Starkey",
    "section": "",
    "text": "About this project :clap: Welcome to our project, where we dive into the dynamic world of professional basketball through the lens of salaries and performance statisics. We will analyize a dataset with NBA player salaries and stats from the 2022-2023 season.\n\nlibrary(tidyverse)\nlibrary(skimr)"
  },
  {
    "objectID": "NBA Project/project.html#mpg-and-a-type-of-cars",
    "href": "NBA Project/project.html#mpg-and-a-type-of-cars",
    "title": "Jake Starkey",
    "section": "MPG and a Type of Cars",
    "text": "MPG and a Type of Cars\nThe following boxplot shows how the distribution of highway MPG (hwy) varies by a type of cars (class) :blue_car: :truck: :minibus:.\n\nggplot(data = mpg) +\n  geom_boxplot(aes(x = class, y = hwy, fill = class),\n               show.legend = F) +\n  labs(x = \"Class\", y = \"Highway\\nMPG\")"
  },
  {
    "objectID": "posts/Restaurant/Restaurant.html",
    "href": "posts/Restaurant/Restaurant.html",
    "title": "Restaurant",
    "section": "",
    "text": "##Question 1\nlibrary(tidyverse)\nlibrary(skimr)\nLoad the data.frame for Question 1.\nrestaurant &lt;- read.csv('https://bcdanl.github.io/data/DOHMH_NYC_Restaurant_Inspection.csv')"
  },
  {
    "objectID": "posts/Restaurant/Restaurant.html#q1a",
    "href": "posts/Restaurant/Restaurant.html#q1a",
    "title": "Restaurant",
    "section": "Q1a",
    "text": "Q1a\nWhat are the mean, standard deviation, first quartile, median, third quartile, and maximum of SCORE for each GRADE of restaurants?\n\nrestaurant %&gt;% \n  group_by(GRADE) %&gt;% \n  skim(SCORE) %&gt;% \n  select(-n_missing)\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n17633\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nGRADE\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nGRADE\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nSCORE\nA\n1\n9.26\n3.42\n0\n7\n10\n12\n13\n‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñá\n\n\nSCORE\nB\n1\n21.03\n4.16\n0\n18\n21\n24\n36\n‚ñÅ‚ñÅ‚ñá‚ñá‚ñÅ\n\n\nSCORE\nC\n1\n38.56\n10.83\n0\n31\n36\n44\n86\n‚ñÅ‚ñá‚ñá‚ñÇ‚ñÅ"
  },
  {
    "objectID": "posts/Restaurant/Restaurant.html#q1b",
    "href": "posts/Restaurant/Restaurant.html#q1b",
    "title": "Restaurant",
    "section": "Q1b",
    "text": "Q1b\nHow many restaurants with a GRADE of A are there in NYC? How much percentage of restaurants in NYC are a GRADE of C?\n\nfreq &lt;- as.data.frame( table(restaurant$GRADE) )\n\nprop &lt;- as.data.frame( 100 * prop.table(table(restaurant$GRADE)) )"
  },
  {
    "objectID": "posts/Restaurant/Restaurant.html#q1c",
    "href": "posts/Restaurant/Restaurant.html#q1c",
    "title": "Restaurant",
    "section": "Q1c",
    "text": "Q1c\nProvide both (1) ggplot code and (2) a simple comment to describe how the distribution of SCORE varies by GRADE and CRITICAL FLAG.\n\nBoxplots\n\n\nggplot(restaurant) +\n  geom_boxplot(aes(x = SCORE, y = GRADE, fill = GRADE) ) +\n  facet_grid( CRITICAL.FLAG ~ . )\n\n\n\n\n\n\n\n\n-Histograms\n\nggplot(restaurant) +\n  geom_histogram(aes(x = SCORE), binwidth = 1 ) +\n  facet_grid( CRITICAL.FLAG ~ GRADE )\n\n\n\n\n\n\n\n\n-Mostly, -The values of SCORE for GRADE A ranges from 0 to 13. -The values of SCORE for GRADE B ranges 13 to 27. -The values of SCORE for GRADE C ranges 24 to 75. -For Not Critical type, two SCORE values around 1 and 12 are most common, while 12 is the single most common SCORE value for Critical type."
  },
  {
    "objectID": "posts/Restaurant/Restaurant.html#q1d",
    "href": "posts/Restaurant/Restaurant.html#q1d",
    "title": "Restaurant",
    "section": "Q1d",
    "text": "Q1d\nProvide both (1) ggplot code and (2) a simple comment to describe how the proportion of CRITICAL FLAG varies by GRADE and BORO.\n\nggplot(restaurant) +\n  geom_bar(aes(x = CRITICAL.FLAG,\n               y = after_stat(prop), group = 1)) +\n  facet_grid( GRADE ~ BORO )\n\n\n\n\n\n\n\n\n-For GRADE A, the probability distribution of CRITICAL FLAG are similar across BOROs.\n-For GRADE B, the restaurants in Staten Island are more likely to be Critical than in other BOROs.\n-For GRADE C, the restaurants in Bronx are more likely to be Critical than in other BOROs."
  },
  {
    "objectID": "posts/Restaurant/Restaurant.html#q1e",
    "href": "posts/Restaurant/Restaurant.html#q1e",
    "title": "Restaurant",
    "section": "Q1e",
    "text": "Q1e\nFor the 10 most common CUISINE DESCRIPTION values, find the CUISINE DESCRIPTION value that has the highest proportion of GRADE A.\n\nq2e &lt;- restaurant %&gt;% \n  group_by(CUISINE.DESCRIPTION) %&gt;% \n  mutate(n = n()) %&gt;% \n  ungroup() %&gt;% \n  filter(dense_rank(-n) &lt;= 10) %&gt;% \n  group_by(CUISINE.DESCRIPTION, GRADE) %&gt;% \n  count() %&gt;% \n  group_by(CUISINE.DESCRIPTION) %&gt;% \n  mutate(prop_A = n / sum(n)) %&gt;% \n  filter(GRADE == 'A') %&gt;% \n  arrange(-prop_A)"
  },
  {
    "objectID": "posts/Restaurant/Restaurant.html#q1f",
    "href": "posts/Restaurant/Restaurant.html#q1f",
    "title": "Restaurant",
    "section": "Q1f",
    "text": "Q1f\n-Find the 3 most common names of restaurants (DBA) in each BORO. -If the third most common DBA values are multiple, please include all the DBA values. -Overall, which DBA value is most common in NYC?\n\nq2f &lt;- restaurant %&gt;% \n  select(DBA, BORO) %&gt;% \n  group_by(BORO, DBA) %&gt;% \n  summarize(n = n()) %&gt;% \n  mutate(ranking = dense_rank(-n)) %&gt;% \n  filter(ranking &lt;= 3) %&gt;% \n  arrange(BORO, ranking)\n\nq2f_ &lt;- restaurant %&gt;% \n  group_by(DBA) %&gt;% \n  count() %&gt;% \n  arrange(-n)\n\nNote that chipotle mexican grill and subway are both the third most popular franchise/chain in Manhattan. üåØ\nOverall, dunkin is the most popular franchise/chain in NYC. üç©"
  },
  {
    "objectID": "posts/Restaurant/Restaurant.html#q1g",
    "href": "posts/Restaurant/Restaurant.html#q1g",
    "title": "Restaurant",
    "section": "Q1g",
    "text": "Q1g\nFor all the DBA values that appear in the result of Q1f, find the DBA value that is most likely to commit critical violation.\n\nq2g &lt;- restaurant %&gt;% \n  filter(DBA %in% q2f$DBA) %&gt;% \n  group_by(DBA, CRITICAL.FLAG) %&gt;% \n  count() %&gt;% \n  group_by(DBA) %&gt;% \n  mutate(lag_n = lag(n),\n         tot = sum(n),\n         prop_crit = lag_n / tot) %&gt;% \n  select(DBA, prop_crit) %&gt;% \n  filter(!is.na(prop_crit)) %&gt;% \n  arrange(-prop_crit)\n\n-Among popular franchises/chains, subway is most likely to commit Critical violation in NYC. ü•™"
  },
  {
    "objectID": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html",
    "href": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html",
    "title": "NFL 2022",
    "section": "",
    "text": "Provide a link for your Github repository ‚úÖ https://github.com/s1arkey/s1arkey.github.io\nAdd a URL for your website (https://YOUR_GITHUB_USERNAME.github.io/) in the About section in your GitHub repository webpage by clicking the setting. ‚úÖ\n\nSee about section in my GitHub repository webpage for answer\nLink to website https://s1arkey.github.io/\n\n\n\n\n\n\nMake sure that your GitHub repository, named YOUR_GITHUB_USERNAME.github.io, is set to public. ‚úÖ\nUpdate your website at https://YOUR_GITHUB_USERNAME.github.io/index.html to:\n\nInclude links to (1) your LinkedIn page, (2) GitHub page (https://github.com/YOUR_GITHUB_USERNAME), and (3) a PDF file of your R√®sume (https://YOUR_GITHUB_USERNAME.github.io/YOUR_RESUME.pdf) ‚úÖ\nOffer a description of yourself, detailing your education background and professional experience. ‚úÖ\nDisplay your own profile picture with your face, not the one shown below. ‚úÖ\n\n\n\n\n\n\nChange the title of your blog. ‚úÖ\n\nThat is, to replace Insightful Analytics with your own blog name.\n\nRemove the blog posts Post With Code, Starwars, and Beer Markets. ‚úÖ\nRevise the Welcome To My Blog post. ‚úÖ\nPost three different blog articles based on data analysis using the following three CSV files: ‚úÖ\n\nhttps://bcdanl.github.io/data/DOHMH_NYC_Restaurant_Inspection.csv\nhttps://bcdanl.github.io/data/spotify_all.csv\nhttps://bcdanl.github.io/data/beer_markets.csv\n\n\nMake sure that each blog post has categories and is associated with a proper image file that is displayed as a thumbnail at the list page of the blog. ‚úÖ\nMake sure that each blog post uses emojis properly. (E.g., üòÑ üç∫ üé∂ üçï) ‚úÖ\nMake sure that each blog post includes its thumbnail image and at least three ggplot figures. ‚úÖ\nYou can refer to the previous DANL 200 Homework Assignments and Exams for your blog posts.\n\n\n##Question 2. NFL in 2022 üèà\n\nAdd a blog post with your answers for Question 2 to your website (https://YOUR_GITHUB_USERNAME.github.io/).\n\nMake sure that your blog post for Question 2 includes all the questionnaires and your answers to them.\nMake sure that your blog post for Question 2 has a section for each sub-question (e.g., Q2a, Q2b) in Question 2, so that the Table of Contents display the section for each questionnaire.\n\nThe following is the data.frame for Question 2.\n\n\nNFL2022_stuffs &lt;- read.csv('https://bcdanl.github.io/data/NFL2022_stuffs.csv')\n\n\nNFL2022_stuffs is the data.frame that contains information about NFL games in year 2022, in which the unit of observation is a single play for each drive in a NFL game.\n\n\n\n\n\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play\ngame_id: Ten digit identifier for NFL game.\ndrive: Numeric drive number in the game.\nweek: Season week.\nposteam: String abbreviation for the team with possession.\nqtr: Quarter of the game (5 is overtime).\nhalf_seconds_remaining: Numeric seconds remaining in the half.\ndown: The down for the given play.\n\nBasically you get four attempts (aka downs) to move the ball 10 yards (by either running with it or passing it).\nIf you make 10 yards then you get another set of four downs.\n\npass: Binary indicator if the play was a pass play.\nwp: Estimated winning probability for the posteam given the current situation at the start of the given play.\n\n\n\n\n\nlibrary(tidyverse)\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.4     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(skimr)\n\nIn data.frame, NFL2022_stuffs, remove observations for which values of posteam is missing.\n\nq2a &lt;- NFL2022_stuffs %&gt;% \n  filter(!is.na(posteam))\n\n\n\n\n\nSummarize the mean value of pass for each posteam when all the following conditions hold:\n\n\nwp is greater than 20% and less than 75%;\ndown is less than or equal to 2; and\nhalf_seconds_remaining is greater than 120.\n\n\nq2b &lt;- NFL2022_stuffs %&gt;% \n  filter(between(wp, 0.2, 0.75),\n         down &lt;= 2,\n         half_seconds_remaining &gt; 120)\n\nmeanvalq2b &lt;- q2b %&gt;% \n  group_by(posteam) %&gt;% \n  summarise(mean_pass = mean(pass, na.rm = TRUE))\n\n\n\n\n\nProvide both (1) a ggplot code with geom_point() using the resulting data.frame in Q2b and (2) a simple comments to describe the mean value of pass for each posteam.\n\nIn the ggplot, reorder the posteam categories based on the mean value of pass in ascending or in descending order.\n\n\n\nmeanvaldesc &lt;- meanvalq2b %&gt;% \n  arrange(desc(mean_pass))\n\nggplot(meanvaldesc, aes(x = mean_pass, y = reorder(posteam, mean_pass))) +\n  geom_point()+\n  labs(x= \"Percentage of Pass Plays\",\n       y= \"Team with possesion\")\n\n\n\n\n\n\n\n\nComments:\n\nCincinnati, Kansas City, Los Angeles Chargers, Buffalo Bills, and Philadelphia eagles had the top 5 highest average percentage of pass plays during the 2022 season.\nAtlanta, Washington, Chicago, New Orleans, and Tennessee had the top 5 lowest average percentage of pass plays during the 2022 season.\n\n\n\n\n\nConsider the following data.frame, NFL2022_epa:\n\n\nNFL2022_epa &lt;- read.csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\n\nVariable description for NFL2022_epa\n\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play\ngame_id: Ten digit identifier for NFL game.\ndrive: Numeric drive number in the game.\nposteam: String abbreviation for the team with possession.\npasser: Name of the player who passed a ball to a receiver by initially taking a three-step drop and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks)\nreceiver: Name of the receiver.\nepa: Expected points added (EPA) by the posteam for the given play.\n\nCreate the data.frame, NFL2022_stuffs_EPA, that includes\n\nAll the variables in the data.frame, NFL2022_stuffs;\nThe variables, passer, receiver, and epa, from the data.frame, NFL2022_epa. by joining the two data.frames.\n\nIn the resulting data.frame, NFL2022_stuffs_EPA, remove observations with NA in passer.\n\nAnswer:\n\nNFL2022_stuffs_EPA &lt;- left_join(NFL2022_stuffs, NFL2022_epa, by = c(\"play_id\", \"game_id\", \"drive\", \"posteam\"))\n\nNFL2022_stuffs_EPA &lt;- NFL2022_stuffs_EPA %&gt;%\n  filter(!is.na(passer))\n\n\n\n\n\nProvide both (1) a single ggplot and (2) a simple comment to describe the NFL weekly trend of weekly mean value of epa for each of the following two passers,\n\n‚ÄúJ.Allen‚Äù\n‚ÄúP.Mahomes‚Äù\n\n\n\ntwo_passers &lt;- c(\"J.Allen\", \"P.Mahomes\")\n\nfiltered_twopassers &lt;- NFL2022_stuffs_EPA %&gt;% \n  filter(passer %in% two_passers)\n\nmean_epa_data &lt;- filtered_twopassers %&gt;% group_by(week, passer) %&gt;% \n  summarise(mean_epa = mean(epa, na.rm = TRUE))\n\n`summarise()` has grouped output by 'week'. You can override using the\n`.groups` argument.\n\nggplot(mean_epa_data, aes(x= week, y= mean_epa, color = passer))+\n  geom_line()+\n  scale_color_manual(values =c(\"J.Allen\" =\"blue\", \"P.Mahomes\"=\"red\"))+\n  labs(x= \"Week\",\n       y= \"Mean value of expected points added (EPA)\")\n\n\n\n\n\n\n\n\nComment: Patrick Mahomes generally had a higher mean value of epa. However, there were a few weeks that Josh Allen had a higher mean value of epa.\n\n\n\nCalculate the difference between the mean value of epa for ‚ÄúJ.Allen‚Äù the mean value of epa for ‚ÄúP.Mahomes‚Äù for each value of week.\n\ndifference_epa &lt;- mean_epa_data %&gt;% \n  pivot_wider(names_from = passer, values_from = mean_epa)\n\ndifference_epa$epa_differnce &lt;- difference_epa$'J.Allen' - difference_epa$'P.Mahomes'\n\nprint(difference_epa)\n\n# A tibble: 22 √ó 4\n# Groups:   week [22]\n    week J.Allen P.Mahomes epa_differnce\n   &lt;int&gt;   &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1     1   0.530    0.698        -0.169 \n 2     2   0.487    0.148         0.339 \n 3     3   0.169    0.246        -0.0763\n 4     4   0.191    0.271        -0.0803\n 5     5   0.627    0.302         0.325 \n 6     6   0.307    0.133         0.173 \n 7     7  NA        0.701        NA     \n 8     8   0.224   NA            NA     \n 9     9  -0.208    0.0965       -0.304 \n10    10   0.161    0.589        -0.429 \n# ‚Ñπ 12 more rows\n\n\n\n\n\n\nSummarize the resulting data.frame in Q2d, with the following four variables:\n\nposteam: String abbreviation for the team with possession.\npasser: Name of the player who passed a ball to a receiver by initially taking a three-step drop, and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks.)\nmean_epa: Mean value of epa in 2022 for each passer\nn_pass: Number of observations for each passer\n\nThen find the top 10 NFL passers in 2022 in terms of the mean value of epa, conditioning that n_pass must be greater than or equal to the third quantile level of n_pass.\n\n\nsummary_data &lt;- NFL2022_stuffs_EPA %&gt;%\n  group_by(posteam, passer) %&gt;%\n  summarise(\n    mean_epa = mean(epa, na.rm = TRUE),\n    n_pass = n()\n  )\n\n`summarise()` has grouped output by 'posteam'. You can override using the\n`.groups` argument.\n\nquantile_threshold_passer &lt;- quantile(summary_data$n_pass, 0.75)\nfiltered_summary_data &lt;- summary_data %&gt;%\n  filter(n_pass &gt;= quantile_threshold_passer)\n\ntop_10_passers &lt;- filtered_summary_data %&gt;%\n  arrange(desc(mean_epa)) %&gt;% \n  head(n=10)\n  \ntop_10_passers\n\n# A tibble: 10 √ó 4\n# Groups:   posteam [10]\n   posteam passer       mean_epa n_pass\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;  &lt;int&gt;\n 1 KC      P.Mahomes      0.286     880\n 2 MIA     T.Tagovailoa   0.234     453\n 3 SF      J.Garoppolo    0.200     348\n 4 BUF     J.Allen        0.172     785\n 5 DET     J.Goff         0.171     661\n 6 CIN     J.Burrow       0.153     854\n 7 DAL     D.Prescott     0.147     529\n 8 PHI     J.Hurts        0.138     672\n 9 JAX     T.Lawrence     0.128     764\n10 CLE     J.Brissett     0.0912    445"
  },
  {
    "objectID": "posts/Spotify all/spotifyall.html",
    "href": "posts/Spotify all/spotifyall.html",
    "title": "Spotify All",
    "section": "",
    "text": "For Question 1, run the following R command to read the CSV file, spotify_all.csv as data.frame, spotify_all:\n\nlibrary(tidyverse)\nlibrary(skimr)\n\n\nspotify_all <- read.csv('https://bcdanl.github.io/data/spotify_all.csv')\n\n\nrmarkdown::paged_table(spotify_all)\n\n\n\n  \n\n\n\nThe data.frame spotify_all includes information about Spotify users' playlists.\n\nThe unit of observation in spotify_all is a track in a music playlist. üé∂"
  },
  {
    "objectID": "posts/Spotify all/spotifyall.html#q1a",
    "href": "posts/Spotify all/spotifyall.html#q1a",
    "title": "Spotify All",
    "section": "Q1a üé∂",
    "text": "Q1a üé∂\n\nFind the ten most popular song. üéµ\n\nA value of a song is defined as a combination of a artist_name value and a track_name value.\nWho are artists for those ten most popular song?\n\n\nQ1a <- spotify_all %>% \n  count(artist_name, track_name) %>% \n  arrange(-n) %>% \n  head(10)\n\nQ1a\n\n        artist_name                          track_name   n\n1             Drake                           One Dance 143\n2    Kendrick Lamar                             HUMBLE. 142\n3  The Chainsmokers                              Closer 129\n4              DRAM         Broccoli (feat. Lil Yachty) 127\n5       Post Malone                     Congratulations 119\n6             Migos Bad and Boujee (feat. Lil Uzi Vert) 117\n7              KYLE             iSpy (feat. Lil Yachty) 115\n8      Lil Uzi Vert                       XO TOUR Llif3 113\n9             Amin√©                            Caroline 107\n10           Khalid                            Location 102"
  },
  {
    "objectID": "posts/Spotify all/spotifyall.html#q1b",
    "href": "posts/Spotify all/spotifyall.html#q1b",
    "title": "Spotify All",
    "section": "Q1b üéº",
    "text": "Q1b üéº\n\nFind the five most popular artist in terms of the number of occurrences in the data.frame, spotify_all.\nWhat is the most popular song for each of the five most popular artist?\n\n\nQ1b <- spotify_all %>% \n  group_by(artist_name) %>% \n  mutate(n_popular_artist = n()) %>% \n  ungroup() %>% \n  mutate( artist_ranking = dense_rank( desc(n_popular_artist) ) ) %>% \n  filter( artist_ranking <= 5) %>% \n  group_by(artist_name, track_name) %>% \n  mutate(n_popular_track = n()) %>% \n  group_by(artist_name) %>% \n  mutate(track_ranking = dense_rank( desc(n_popular_track) ) ) %>% \n  filter( track_ranking <= 2) %>%   # I just wanted to see the top two tracks for each artist\n  select(artist_name, artist_ranking, n_popular_artist, track_name, track_ranking, n_popular_track) %>% \n  distinct() %>% \n  arrange(artist_ranking, track_ranking)\n\nQ1b\n\n# A tibble: 10 √ó 6\n# Groups:   artist_name [5]\n   artist_name    artist_ranking n_popular_artist track_name  track_ranking\n   <chr>                   <int>            <int> <chr>               <int>\n 1 Drake                       1             2715 One Dance               1\n 2 Drake                       1             2715 Jumpman                 2\n 3 Kanye West                  2             1065 Gold Digger             1\n 4 Kanye West                  2             1065 Stronger                2\n 5 Kendrick Lamar              3             1035 HUMBLE.                 1\n 6 Kendrick Lamar              3             1035 DNA.                    2\n 7 Rihanna                     4              915 Needed Me               1\n 8 Rihanna                     4              915 Work                    2\n 9 The Weeknd                  5              913 Starboy                 1\n10 The Weeknd                  5              913 The Hills               2\n# ‚Ñπ 1 more variable: n_popular_track <int>"
  },
  {
    "objectID": "posts/Spotify all/spotifyall.html#q1c",
    "href": "posts/Spotify all/spotifyall.html#q1c",
    "title": "Spotify All",
    "section": "Q1c üéπ",
    "text": "Q1c üéπ\nProvide both (1) ggplot codes and (2) a couple of sentences to describe the relationship between pos and the ten most popular artists.\n\nQ1c <- spotify_all %>% \n  group_by(artist_name) %>% \n  mutate(n_popular_artist = n()) %>% \n  ungroup() %>% \n  mutate( artist_ranking = dense_rank( desc(n_popular_artist) ) ) %>% \n  filter( artist_ranking <= 10) \n  \n# boxplot\nggplot(Q1c,\n       aes(x = pos, y = fct_reorder(artist_name, -artist_ranking)) ) +\n  geom_boxplot() +\n  stat_summary(\n    fun = mean,\n    color = 'red'\n  )\n\n\n\n\n\nggplot(Q1c) +\n  geom_histogram(aes(x = pos), binwidth = 1) + \n  facet_grid(fct_reorder(artist_name, artist_ranking) ~ .  , switch = \"y\") +\n  theme(strip.text.y.left = element_text(angle = 0))\n\n\n\n\n\nAll are skewed right.\n\nUsers tend to locate these popular artists' songs early in their playlist.\n\nThe distribution of pos does not seem to vary a lot across the ten most popular artists.\nAnything noticeable can be mentioned."
  },
  {
    "objectID": "posts/Spotify all/spotifyall.html#q1d",
    "href": "posts/Spotify all/spotifyall.html#q1d",
    "title": "Spotify All",
    "section": "Q1d üéµ",
    "text": "Q1d üéµ\nCreate the data.frame with pid-artist level of observations with the following four variables:\n\npid: playlist id\nplaylist_name: name of playlist\nartist: name of the track's primary artist, which appears only once within a playlist\nn_artist: number of occurrences of artist within a playlist\n\n\nQ1d <- spotify_all %>% \n  count(pid, playlist_name, artist_name) %>% \n  rename(n_artist = n) %>% \n  arrange(pid, -n_artist, artist_name)\n\n\nrmarkdown::paged_table(Q1d)"
  },
  {
    "objectID": "posts/Favorite Artist /Favorite_Artists.html",
    "href": "posts/Favorite Artist /Favorite_Artists.html",
    "title": "Favorite Artist",
    "section": "",
    "text": "The purpose of this blog is to give reader‚Äôs insight into my favorite artist‚Äôs within the Spotify DataFrame\nBelow is the spotify DataFrame that reads the file spotify_all.csv containing data of Spotify users‚Äô playlist information (Source: Spotify Million Playlist Dataset Challenge)..\n\nimport pandas as pd\nspotify = pd.read_csv('https://bcdanl.github.io/data/spotify_all.csv')\nspotify\n\n\n\n  \n    \n\n\n  \n    \n      \n      pid\n      playlist_name\n      pos\n      artist_name\n      track_name\n      duration_ms\n      album_name\n    \n  \n  \n    \n      0\n      0\n      Throwbacks\n      0\n      Missy Elliott\n      Lose Control (feat. Ciara & Fat Man Scoop)\n      226863\n      The Cookbook\n    \n    \n      1\n      0\n      Throwbacks\n      1\n      Britney Spears\n      Toxic\n      198800\n      In The Zone\n    \n    \n      2\n      0\n      Throwbacks\n      2\n      Beyonc√©\n      Crazy In Love\n      235933\n      Dangerously In Love (Alben f√ºr die Ewigkeit)\n    \n    \n      3\n      0\n      Throwbacks\n      3\n      Justin Timberlake\n      Rock Your Body\n      267266\n      Justified\n    \n    \n      4\n      0\n      Throwbacks\n      4\n      Shaggy\n      It Wasn't Me\n      227600\n      Hot Shot\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      198000\n      999998\n      ‚úùÔ∏è\n      6\n      Chris Tomlin\n      Waterfall\n      209573\n      Love Ran Red\n    \n    \n      198001\n      999998\n      ‚úùÔ∏è\n      7\n      Chris Tomlin\n      The Roar\n      220106\n      Love Ran Red\n    \n    \n      198002\n      999998\n      ‚úùÔ∏è\n      8\n      Crowder\n      Lift Your Head Weary Sinner (Chains)\n      224666\n      Neon Steeple\n    \n    \n      198003\n      999998\n      ‚úùÔ∏è\n      9\n      Chris Tomlin\n      We Fall Down\n      280960\n      How Great Is Our God: The Essential Collection\n    \n    \n      198004\n      999998\n      ‚úùÔ∏è\n      10\n      Caleb and Kelsey\n      10,000 Reasons / What a Beautiful Name\n      178189\n      10,000 Reasons / What a Beautiful Name\n    \n  \n\n198005 rows √ó 7 columns"
  },
  {
    "objectID": "posts/Favorite Artist /Favorite_Artists.html#variable-discription",
    "href": "posts/Favorite Artist /Favorite_Artists.html#variable-discription",
    "title": "Favorite Artist",
    "section": "Variable Discription",
    "text": "Variable Discription\n\npid: playlist ID; unique ID for playlist\nplaylist_name: a name of playlist\npos: a position of the track within a playlist (starting from 0)\nartist_name: name of the track‚Äôs primary artist\ntrack_name: name of the track\nduration_ms: duration of the track in milliseconds\nalbum_name: name of the track‚Äôs album ## Occurances\n\n\nartist_count = spotify['artist_name'].value_counts()\nartist_count\n\nDrake                2715\nKanye West           1065\nKendrick Lamar       1035\nRihanna               915\nThe Weeknd            913\n                     ... \nLuna City Express       1\nNinetoes                1\nRhemi                   1\nJamie 3:26              1\nCaleb and Kelsey        1\nName: artist_name, Length: 18866, dtype: int64\n\n\n\nThe above code counts the occurences of each artist as you can see, Kanye West appears the most in playlists and he is my favorite artist."
  },
  {
    "objectID": "posts/Favorite Artist /Favorite_Artists.html#favorite-artist-data-frame",
    "href": "posts/Favorite Artist /Favorite_Artists.html#favorite-artist-data-frame",
    "title": "Favorite Artist",
    "section": "Favorite Artist Data Frame",
    "text": "Favorite Artist Data Frame\n\nfavorite_artists = spotify[spotify['artist_name'].isin(['Kanye West', '21 Savage','Drake'])]\nfavorite_artists\n\n\n\n  \n    \n\n\n  \n    \n      \n      pid\n      playlist_name\n      pos\n      artist_name\n      track_name\n      duration_ms\n      album_name\n    \n  \n  \n    \n      522\n      10\n      abby\n      8\n      Drake\n      Portland\n      236614\n      More Life\n    \n    \n      544\n      10\n      abby\n      30\n      Drake\n      Preach\n      236973\n      If You're Reading This It's Too Late\n    \n    \n      570\n      10\n      abby\n      56\n      Drake\n      Headlines\n      235986\n      Take Care\n    \n    \n      638\n      11\n      VIBE\n      52\n      Drake\n      Houstatlantavegas\n      290426\n      So Far Gone\n    \n    \n      639\n      11\n      VIBE\n      53\n      Drake\n      Runnin Away For Good\n      292666\n      The Drake LP\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      197564\n      999990\n      Drake\n      0\n      Drake\n      One Dance\n      173986\n      Views\n    \n    \n      197565\n      999990\n      Drake\n      1\n      Drake\n      Fake Love\n      210937\n      More Life\n    \n    \n      197566\n      999990\n      Drake\n      2\n      Drake\n      Pop Style\n      212946\n      Views\n    \n    \n      197567\n      999990\n      Drake\n      3\n      Drake\n      Hotline Bling\n      267066\n      Views\n    \n    \n      197568\n      999990\n      Drake\n      4\n      Drake\n      Legend\n      241853\n      If You're Reading This It's Too Late\n    \n  \n\n4124 rows √ó 7 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nThe above code filters the DataFrame to show only the songs by my three favorite artists: Drake, Kanye West, and 21 Savage"
  },
  {
    "objectID": "posts/Favorite Artist /Favorite_Artists.html#favorite-artists-occurances",
    "href": "posts/Favorite Artist /Favorite_Artists.html#favorite-artists-occurances",
    "title": "Favorite Artist",
    "section": "Favorite Artists Occurances",
    "text": "Favorite Artists Occurances\n\nfavorite_count = favorite_artists['artist_name'].value_counts()\nfavorite_count\n\nDrake         2715\nKanye West    1065\n21 Savage      344\nName: artist_name, dtype: int64\n\n\n\nThis code shows the number of occurrences that my three favorite artists have in the data set"
  },
  {
    "objectID": "posts/Favorite Artist /Favorite_Artists.html#favorite-artists-track-duration",
    "href": "posts/Favorite Artist /Favorite_Artists.html#favorite-artists-track-duration",
    "title": "Favorite Artist",
    "section": "Favorite Artist‚Äôs Track Duration",
    "text": "Favorite Artist‚Äôs Track Duration\n\nsorted_fav_artists = favorite_artists.sort_values(by = 'duration_ms', ascending = False)\nno_duplicates = sorted_fav_artists.drop_duplicates(subset=['artist_name', 'track_name'])\nlongest_tracks = no_duplicates[['artist_name', 'track_name', 'duration_ms']].head(10)\nlongest_tracks\n\n\n\n  \n    \n\n\n  \n    \n      \n      artist_name\n      track_name\n      duration_ms\n    \n  \n  \n    \n      67145\n      Kanye West\n      Last Call\n      760973\n    \n    \n      119752\n      Kanye West\n      Runaway\n      547733\n    \n    \n      123616\n      Kanye West\n      Blame Game\n      469866\n    \n    \n      123594\n      Drake\n      Cameras / Good Ones Go Interlude - Medley\n      434960\n    \n    \n      47541\n      Drake\n      Pound Cake / Paris Morton Music 2\n      433800\n    \n    \n      138846\n      21 Savage\n      7 Min Freestyle\n      431586\n    \n    \n      65122\n      Drake\n      Shut It Down\n      419306\n    \n    \n      162482\n      Kanye West\n      So Appalled\n      397666\n    \n    \n      131325\n      Drake\n      Uptown\n      381240\n    \n    \n      55630\n      Kanye West\n      Monster\n      378893\n    \n  \n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nThe above code sorts the DateFrame containing only tracks from my favorite artists by the length of their songs\nIt then gets rid of any duplicates so I only see one of each song\nThen I see the top 10 longest tracks by my three favorite artists\nKanye Takes the three longest songs out of my favorite artists."
  },
  {
    "objectID": "posts/Favorite Artist /Favorite_Artists.html#favorite-artists-average-position",
    "href": "posts/Favorite Artist /Favorite_Artists.html#favorite-artists-average-position",
    "title": "Favorite Artist",
    "section": "Favorite Artist‚Äôs Average Position",
    "text": "Favorite Artist‚Äôs Average Position\n\nfav_artist_name = favorite_artists['artist_name'].unique()\nartist_tracks = spotify[spotify['artist_name'].isin(fav_artist_name)]\navg_pos = artist_tracks.groupby('artist_name')['pos'].mean()\navg_pos\n\nartist_name\n21 Savage     57.776163\nDrake         57.143278\nKanye West    51.292958\nName: pos, dtype: float64\n\n\n\nThe above code gathers the average position of tracks within a playlist for each of my three favorite artists within the Spotify DataFrame"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Thanks for tuning into my project! My blogs break down several data frames. Currently you are on my welcome post. The other blogs are Beer Markets, Spotify, Restaurants, and NFL in 2022.\nDuring free time I like to hangout with friends. Other hobbies include lifting, playing lacrosse, skiing, and going on hikes.\nI hope you enjoy my website."
  },
  {
    "objectID": "posts/Beer Markets /beer-markets.html",
    "href": "posts/Beer Markets /beer-markets.html",
    "title": "Beer Markets",
    "section": "",
    "text": "For Question 1, run the following R command to read the beer market data.\n\nlibrary(tidyverse)\nlibrary(skimr)\n\n\nbeer_mkts &lt;- read.csv('https://bcdanl.github.io/data/beer_markets.csv')\n\n\nrmarkdown::paged_table(beer_mkts)\n\n\n  \n\n\n\n-Each observation in beer_mkts is a household-level transaction record for a purchase of beer."
  },
  {
    "objectID": "posts/Beer Markets /beer-markets.html#q1a",
    "href": "posts/Beer Markets /beer-markets.html#q1a",
    "title": "Beer Markets",
    "section": "Q1a",
    "text": "Q1a\n-Find the top 5 markets in terms of the total beer_floz. -Find the top 5 markets in terms of the total beer_floz of BUD LIGHT. -Find the top 5 markets in terms of the total beer_floz of BUSCH LIGHT. -Find the top 5 markets in terms of the total beer_floz of COORS LIGHT. -Find the top 5 markets in terms of the total beer_floz of MILLER LITE. -Find the top 5 markets in terms of the total beer_floz of NATURAL LIGHT.\n\nQ1a1 &lt;- beer_mkts %&gt;% \n   group_by(market) %&gt;% \n   summarize(beer_floz_tot = sum(beer_floz, na.rm = T)) %&gt;% \n   arrange(-beer_floz_tot) %&gt;% \n   slice(1:5)\n\nQ1a_bud &lt;- beer_mkts %&gt;% \n  filter(brand == \"BUD LIGHT\") %&gt;% \n  group_by(market) %&gt;% \n  summarize(beer_floz_tot = sum(beer_floz, na.rm = T)) %&gt;% \n  arrange(-beer_floz_tot) %&gt;% \n  slice(1:5)\n\nQ1a_busch &lt;- beer_mkts %&gt;% \n  filter(brand == \"BUSCH LIGHT\") %&gt;% \n  group_by(market) %&gt;% \n  summarize(beer_floz_tot = sum(beer_floz, na.rm = T)) %&gt;% \n  arrange(-beer_floz_tot) %&gt;% \n  slice(1:5)\n\nQ1a_coors &lt;- beer_mkts %&gt;% \n  filter(brand == \"COORS LIGHT\") %&gt;% \n  group_by(market) %&gt;% \n  summarize(beer_floz_tot = sum(beer_floz, na.rm = T)) %&gt;% \n  arrange(-beer_floz_tot) %&gt;% \n  slice(1:5)\n\nQ1a_miller &lt;- beer_mkts %&gt;% \n  filter(brand == \"MILLER LITE\") %&gt;% \n  group_by(market) %&gt;% \n  summarize(beer_floz_tot = sum(beer_floz, na.rm = T)) %&gt;% \n  arrange(-beer_floz_tot) %&gt;% \n  slice(1:5)\n\nQ1a_natural &lt;- beer_mkts %&gt;% \n  filter(brand == \"NATURAL LIGHT\") %&gt;% \n  group_by(market) %&gt;% \n  summarize(beer_floz_tot = sum(beer_floz, na.rm = T)) %&gt;% \n  arrange(-beer_floz_tot) %&gt;% \n  slice(1:5)"
  },
  {
    "objectID": "posts/Beer Markets /beer-markets.html#q1b",
    "href": "posts/Beer Markets /beer-markets.html#q1b",
    "title": "Beer Markets",
    "section": "Q1büçª",
    "text": "Q1büçª\n-For households that purchased BUD LIGHT at least once, what fraction of households did purchase only BUD LIGHT?\n-For households that purchased BUSCH LIGHT at least once, what fraction of households did purchase only BUSCH LIGHT?\n-For households that purchased COORS LIGHT at least once, what fraction of households did purchase only COORS LIGHT?\n-For households that purchased MILLER LITE at least once, what fraction of households did purchase only MILLER LITE?\n-For households that purchased NATURAL LIGHT at least once, what fraction of households did purchase only NATURAL LIGHT?\n-Which beer brand does have the largest proportion of such loyal consumers?\n\nq1b &lt;- beer_mkts %&gt;% \n  mutate(bud = ifelse(brand==\"BUD LIGHT\", 1, 0), # 1 if brand==\"BUD LIGHT\"; 0 otherwise\n         busch = ifelse(brand==\"BUSCH LIGHT\", 1, 0),\n         coors = ifelse(brand==\"COORS LIGHT\", 1, 0),\n         miller = ifelse(brand==\"MILLER LITE\", 1, 0),\n         natural = ifelse(brand==\"NATURAL LIGHT\", 1, 0),\n         .after = hh) %&gt;% \n  select(hh:natural) %&gt;%  # select the variables we need\n  group_by(hh) %&gt;% \n  summarise(n_transactions = n(), # number of beer transactions for each hh\n            n_bud = sum(bud), # number of BUD LIGHT transactions for each hh\n            n_busch = sum(busch), \n            n_coors = sum(coors), \n            n_miller = sum(miller), \n            n_natural = sum(natural) \n  ) %&gt;% \n  summarise(loyal_bud = sum(n_transactions == n_bud) / sum(n_bud &gt; 0), \n              # sum(n_transactions == n_bud) : the number of households that purchased BUD LIGHT only\n              # sum(n_bud &gt; 0) : the number of households that purchased BUD LIGHT at least once.\n            loyal_busch = sum(n_transactions == n_busch) / sum(n_busch &gt; 0),\n            loyal_coors = sum(n_transactions == n_coors) / sum(n_coors &gt; 0),\n            loyal_miller = sum(n_transactions == n_miller) / sum(n_miller &gt; 0),\n            loyal_natural = sum(n_transactions == n_natural) / sum(n_natural &gt; 0)\n  )\n\nq1b\n\n# A tibble: 1 √ó 5\n  loyal_bud loyal_busch loyal_coors loyal_miller loyal_natural\n      &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n1     0.660       0.473       0.639        0.631         0.510"
  },
  {
    "objectID": "posts/Beer Markets /beer-markets.html#q1c",
    "href": "posts/Beer Markets /beer-markets.html#q1c",
    "title": "Beer Markets",
    "section": "Q1c üçª",
    "text": "Q1c üçª\n-For each household, calculate the number of beer transactions. -For each household, calculate the proportion of each beer brand choice.\n\nq1c &lt;- beer_mkts %&gt;% \n  count(hh, brand) %&gt;% \n  group_by(hh) %&gt;% \n  mutate(n_tot = sum(n)) %&gt;%  \n  arrange(hh, brand) %&gt;% \n  mutate( prop = n / n_tot ) \n\nq1c\n\n# A tibble: 13,202 √ó 5\n# Groups:   hh [10,408]\n        hh brand           n n_tot  prop\n     &lt;int&gt; &lt;chr&gt;       &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n 1 2000235 BUD LIGHT       1     1 1    \n 2 2000417 COORS LIGHT     8     8 1    \n 3 2000711 COORS LIGHT    13    13 1    \n 4 2000946 BUD LIGHT       1     2 0.5  \n 5 2000946 MILLER LITE     1     2 0.5  \n 6 2001521 BUD LIGHT       6    11 0.545\n 7 2001521 COORS LIGHT     3    11 0.273\n 8 2001521 MILLER LITE     2    11 0.182\n 9 2001531 BUSCH LIGHT     1     1 1    \n10 2001581 BUSCH LIGHT     5     5 1    \n# ‚Ñπ 13,192 more rows"
  },
  {
    "objectID": "posts/Python Basics /PythonBasics.html",
    "href": "posts/Python Basics /PythonBasics.html",
    "title": "Python Basics",
    "section": "",
    "text": "*A value is datum (literal) such as a number or text\n*There are different types of values:\n*352.3 is known as a float or double;\n*22 is an integer;\n*‚ÄúHello World!‚Äù is a string.\n\nlist_example =  [10, 1.23, \"like this\", True, None]\nprint(list_example)\ntype(list_example)\n\n[10, 1.23, 'like this', True, None]\n\n\nlist\n\n\n[10, 1.23, ‚Äòlike this‚Äô, True, None]\n*The most. basic built-in data types that we‚Äôll need to know about are: integers, 10 floats, 1.23 strings, ‚Äúlike this‚Äù booleans, True nothing, None\n*Python also has a built-in type of data container called a list (ex. [10,15,20]) that can contain anything, even different types\n##Values, Variables, and Types\n\na = 10\nprint(a)\n\n10\n\n\n*A variable is a name that refers to a value.\n**We can think of a variable as a box that has a value, or multiple values, packed inside it A variable is just a name!\n*Sometimes you will hear variables referred to as objects.\n*Everything that is not a literal value, such as 10, is an object\n##Assignment (=)\n\n# Here we assign the integer value 5 to the variable x.\nx = 5   \n\n# Now we can use the variable x in the next line.\ny = x + 12  \ny\n\n17\n\n\n*In Python, we use = to assign a value to a variable\n*In math, = means equality of both sides\n*In programs, = means assignment: assign the value on the right side to the variable on the left side.\n*In programming code, everything on the right side needs to have a value.\n*The right side can be a literal value, or a variable that has already been assigned a value, or a combination.\n*When Python reads y= x + 12, it does the following: Sees the = in the middle.Knows that this is an assignment.\n*Calculates the right side (gets the value of the object referred to by x and adds it to 12).\n*Assigns the result to the left-side variable, y.\n##Code and Comment Style\n*The two main principles for coding and managing data are: Make things easier for your future self. Don‚Äôt trust your future self.\n*The # mark is Google Colab‚Äôs comment character The # character has many names: hash, sharp, pound, or octothorpe. The # indicates that the rest of the line is to be ignored. **Write comments before the line that you want the comment to apply to.\n*Consider adding more comments on code cells and their results using text cells.\n##Brackets *There are several kinds of brackets in Python, including [], {}, and ().\n\nvector = ['a', 'b']\nvector[0]\n\n'a'\n\n\n*[] is used to denote a list or to signify accessing a position using an index\n\n{'a', 'b'}  # set\n{'first_letter': 'a', 'second_letter': 'b'}  # dictionary\n\n{'first_letter': 'a', 'second_letter': 'b'}\n\n\n{‚Äòfirst_letter‚Äô: ‚Äòa‚Äô, ‚Äòsecond_letter‚Äô: ‚Äòb‚Äô} {} is used to denote a set or a dictionary (with key-value pairs)\n*() is used to denote a tuple, or the arguments to a function, ex. function(x) where x is the input passed to the function ##Q1\n\n(2**5/(7*(4-2**3)))\n\n-1.1428571428571428\n\n\n##Q2\n\n20 == '20'\n\nFalse\n\n\n*This is saying 20 is not equal to ‚Äò20‚Äô because they are different data types (int vs string)\n\nx = 4.0\ny = .5\nz = 3*y - x\n\nx &lt; y or 3*y &lt; x\n\nTrue\n\n\nTrue This says the expression is true since 3.5 &lt; 4\n##Q3\n\nfare = \"$10.00\"\ntip = \"2.00$\"\ntax = \"$ 0.80\"\n\nWrite a Python code that uses slicing and the print() function to print out the following message:\nThe total trip cost is: $12.80\n\ntotal =fare = \"$10.00\"\ntip = \"2.00$\"\ntax = \"$ 0.80\"\ntotal = fare[0:2] + tip[0] + tax[3:6]\nprint(\"The total trip cost is:\", total)\n\n#The total trip cost is: $12.80The total trip cost is:\", total)\n\nThe total trip cost is: $12.80\n\n\n##Q4\n\nlist_variable = [100, 144, 169, 1000, 8]\n\nWrite a Python code that uses print() and max() functions to print out the largest value in the list, list_variable, as follows:\nThe largest value in the list is: 1000\n\nlist_variable = [100,144,169,1000,8]\nx =max(list_variable)\nprint('The largest value in the list is:',x)\n\n#The largest value in the list is: 1000\n\nThe largest value in the list is: 1000\n\n\nThe largest value in the list is: 1000 ##Q5 Import the pandas library as pd. Install the itables package. *From itables, import the function init_notebook_mode and show.\n\nimport pandas as pd\n!pip install itables\nfrom itables import init_notebook_mode\nfrom itables import show\n\nRequirement already satisfied: itables in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (1.6.3)\nRequirement already satisfied: IPython in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from itables) (8.15.0)\nRequirement already satisfied: pandas in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from itables) (2.0.3)\nRequirement already satisfied: numpy in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from itables) (1.24.3)\nRequirement already satisfied: backcall in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (0.2.0)\nRequirement already satisfied: decorator in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (5.1.1)\nRequirement already satisfied: jedi&gt;=0.16 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (0.18.1)\nRequirement already satisfied: matplotlib-inline in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (0.1.6)\nRequirement already satisfied: pickleshare in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.37,&lt;3.1.0,&gt;=3.0.30 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (3.0.36)\nRequirement already satisfied: pygments&gt;=2.4.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (2.15.1)\nRequirement already satisfied: stack-data in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (0.2.0)\nRequirement already satisfied: traitlets&gt;=5 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (5.7.1)\nRequirement already satisfied: pexpect&gt;4.3 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (4.8.0)\nRequirement already satisfied: appnope in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (0.1.2)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from pandas-&gt;itables) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from pandas-&gt;itables) (2023.3.post1)\nRequirement already satisfied: tzdata&gt;=2022.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from pandas-&gt;itables) (2023.3)\nRequirement already satisfied: parso&lt;0.9.0,&gt;=0.8.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from jedi&gt;=0.16-&gt;IPython-&gt;itables) (0.8.3)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from pexpect&gt;4.3-&gt;IPython-&gt;itables) (0.7.0)\nRequirement already satisfied: wcwidth in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,&lt;3.1.0,&gt;=3.0.30-&gt;IPython-&gt;itables) (0.2.5)\nRequirement already satisfied: six&gt;=1.5 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;itables) (1.16.0)\nRequirement already satisfied: executing in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from stack-data-&gt;IPython-&gt;itables) (0.8.3)\nRequirement already satisfied: asttokens in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from stack-data-&gt;IPython-&gt;itables) (2.0.5)\nRequirement already satisfied: pure-eval in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from stack-data-&gt;IPython-&gt;itables) (0.2.2)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jake Starkey",
    "section": "",
    "text": "Thanks for tuning into my project!\nUnder the project tab, the code breaks down, ESG (Environmental, Social, and Governance) data highlighting the importance of integrating sustainability considerations into financial analysis.\nUnder the blog tab, You will find different homework projects from multiple classes.Favorite Artist, Python Basics, Spotify All, Restaurant, NFL 2022, and Beer Markets all break down data frames using variables to answer questions."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Jake Starkey",
    "section": "Education",
    "text": "Education\nMajor in Economics, Data Analytics minor|State University of New York at Geneseo | Geneseo, NY  Major in Economics | Aug 2022 - May 2026"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Jake Starkey",
    "section": "Experience",
    "text": "Experience\nStudent | August 2022 - May 2026"
  },
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Jake Starkeys blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nFavorite Artist\n\n\n\n\n\n\n\n\nMar 6, 2024\n\n\nJake Starkey\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nPython Basics\n\n\n\n\n\n\n\n\nFeb 18, 2024\n\n\nJake Starkey\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nSpotify All\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nJake Starkey\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nRestaurant\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nJake Starkey\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nNFL 2022\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nJake Starkey\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nBeer Markets\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nJake Starkey\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\nOct 27, 2023\n\n\nJake Starkey\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "danl-210-quarto.html",
    "href": "danl-210-quarto.html",
    "title": "DANL 210: Data Preparation and Management",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\nprint('Hello, World!')\n\nHello, World!\n\n\n\n\n\nIn Python, variables can store data of different types without explicitly declaring the type.\nFor example:\n\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\n\nfloat_variable\n\n10.5\n\n\n\n\n\nPython supports the usual logical conditions from mathematics:\n\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a < b\n# Less than or equal to: a <= b\n# Greater than: a > b\n# Greater than or equal to: a >= b\n\nThese conditions can be used in several ways, most commonly in ‚Äòif statements‚Äô and loops.\n\n# if statement:\nif 5 > 2:\n    print('Five is greater than two!')\n\nFive is greater than two!\n\n\n\n\n\nA function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\n# Defining a function:\ndef my_function():\n    print('Hello from a function')\n\n# Calling a function:\nmy_function()\n\nHello from a function\n\n\n\n\n\nA list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\n\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}"
  },
  {
    "objectID": "danl-210-quarto.html#import-python-libraries",
    "href": "danl-210-quarto.html#import-python-libraries",
    "title": "DANL 210: Data Preparation and Management",
    "section": "2.1 Import Python libraries",
    "text": "2.1 Import Python libraries\n!pip install dtale to install dtale library\n\n!pip install dtale\nimport pandas as pd\nimport dtale\n\nRequirement already satisfied: dtale in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (3.9.0)\n\n\nRequirement already satisfied: dash-colorscales in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (0.0.4)\nRequirement already satisfied: dash-daq in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (0.5.0)\nRequirement already satisfied: Flask-Compress in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (1.14)\nRequirement already satisfied: future>=0.14.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (0.18.3)\nRequirement already satisfied: kaleido in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (0.2.1)\nRequirement already satisfied: missingno in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (0.5.2)\nRequirement already satisfied: pandas in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (2.0.3)\nRequirement already satisfied: squarify in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (0.4.3)\nRequirement already satisfied: strsimpy in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (0.2.1)\nRequirement already satisfied: six in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (1.16.0)\nRequirement already satisfied: xlrd in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (2.0.1)\nRequirement already satisfied: beautifulsoup4 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (4.12.2)\nRequirement already satisfied: certifi in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (2024.2.2)\nRequirement already satisfied: flask-ngrok in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (0.0.25)\nRequirement already satisfied: lz4 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (4.3.2)\nRequirement already satisfied: cycler in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (0.11.0)\nRequirement already satisfied: dash-bootstrap-components<=1.3.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (1.3.1)\n\n\nRequirement already satisfied: dash in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (2.14.2)\nRequirement already satisfied: seaborn in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (0.12.2)\nRequirement already satisfied: statsmodels in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (0.14.0)\nRequirement already satisfied: werkzeug in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (2.2.3)\nRequirement already satisfied: networkx in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (3.1)\nRequirement already satisfied: scikit-learn in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (1.3.0)\nRequirement already satisfied: numpy in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (1.24.3)\nRequirement already satisfied: openpyxl!=3.2.0b1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (3.0.10)\nRequirement already satisfied: xarray in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (2023.6.0)\nRequirement already satisfied: et-xmlfile in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (1.1.0)\nRequirement already satisfied: plotly in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (5.9.0)\nRequirement already satisfied: Flask<2.3 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (2.2.2)\nRequirement already satisfied: itsdangerous in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (2.0.1)\nRequirement already satisfied: requests in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (2.31.0)\nRequirement already satisfied: contourpy in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (1.0.5)\nRequirement already satisfied: matplotlib in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (3.7.2)\nRequirement already satisfied: scipy!=1.12.0rc1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dtale) (1.11.1)\nRequirement already satisfied: dash-html-components==2.0.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dash->dtale) (2.0.0)\nRequirement already satisfied: dash-core-components==2.0.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dash->dtale) (2.0.0)\nRequirement already satisfied: dash-table==5.0.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dash->dtale) (5.0.0)\nRequirement already satisfied: typing-extensions>=4.1.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dash->dtale) (4.11.0)\nRequirement already satisfied: retrying in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dash->dtale) (1.3.4)\nRequirement already satisfied: ansi2html in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dash->dtale) (1.9.1)\nRequirement already satisfied: nest-asyncio in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dash->dtale) (1.5.6)\nRequirement already satisfied: setuptools in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dash->dtale) (68.0.0)\nRequirement already satisfied: importlib-metadata in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from dash->dtale) (7.0.1)\nRequirement already satisfied: Jinja2>=3.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from Flask<2.3->dtale) (3.1.2)\nRequirement already satisfied: click>=8.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from Flask<2.3->dtale) (8.0.4)\n\n\nRequirement already satisfied: tenacity>=6.2.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from plotly->dtale) (8.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from werkzeug->dtale) (2.1.1)\nRequirement already satisfied: soupsieve>1.2 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->dtale) (2.4)\nRequirement already satisfied: brotli in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from Flask-Compress->dtale) (1.1.0)\nRequirement already satisfied: fonttools>=4.22.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from matplotlib->dtale) (4.25.0)\n\n\nRequirement already satisfied: kiwisolver>=1.0.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from matplotlib->dtale) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from matplotlib->dtale) (23.1)\nRequirement already satisfied: pillow>=6.2.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from matplotlib->dtale) (10.0.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from matplotlib->dtale) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from matplotlib->dtale) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from pandas->dtale) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from pandas->dtale) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from requests->dtale) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from requests->dtale) (3.4)\n\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from requests->dtale) (1.26.16)\nRequirement already satisfied: joblib>=1.1.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from scikit-learn->dtale) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from scikit-learn->dtale) (2.2.0)\nRequirement already satisfied: patsy>=0.5.2 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from statsmodels->dtale) (0.5.3)\n\n\nRequirement already satisfied: zipp>=0.5 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from importlib-metadata->dash->dtale) (3.11.0)\n\n\n\noj = pd.read_csv('https://bcdanl.github.io/data/dominick_oj.csv')\n\n\n\nCode!\noj\n\n\n\n\n\n\n  \n    \n      \n      sales\n      price\n      brand\n      ad\n    \n  \n  \n    \n      0\n      8256.0\n      3.87\n      tropicana\n      0\n    \n    \n      1\n      6144.0\n      3.87\n      tropicana\n      0\n    \n    \n      2\n      3840.0\n      3.87\n      tropicana\n      0\n    \n    \n      3\n      8000.0\n      3.87\n      tropicana\n      0\n    \n    \n      4\n      8896.0\n      3.87\n      tropicana\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      28942\n      2944.0\n      2.00\n      dominicks\n      0\n    \n    \n      28943\n      4928.0\n      1.94\n      dominicks\n      0\n    \n    \n      28944\n      13440.0\n      1.59\n      dominicks\n      0\n    \n    \n      28945\n      55680.0\n      1.49\n      dominicks\n      0\n    \n    \n      28946\n      7040.0\n      1.75\n      dominicks\n      0\n    \n  \n\n28947 rows √ó 4 columns\n\n\n\n\n# dtale.show(oj)"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "DANL Project",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nbalance_sheet = pd.read_csv('yfinance-balance-sheet.csv')\nstock_data = pd.read_csv('yfinance-history.csv')\nesg_proj_data = pd.read_csv('esg_proj_data.csv')"
  },
  {
    "objectID": "project.html#introduction",
    "href": "project.html#introduction",
    "title": "DANL Project",
    "section": "0.2 1 Introduction",
    "text": "0.2 1 Introduction\nESG(Environmental, Social, and Governance) factors are increasingly being considered by investors for making informed investment decisions. Understanding the relationship between ESG metrics and financial performance can provide valuable insights into a company‚Äôs sustainability and long-term viability.\nThis project aims to analyze the relationship between ESG metrics and financial/accounting data to identify any correlations and trends that may exist. By doing so, we seek to provide investors with a better understanding of how ESG factors impact financial performance and assist them in making more sustainable investment decisions.\nThe project utilizes Python scripts to collect financial, accounting, and ESG data. The financial and accounting data is obtained using the yfinance library, while Selenium is employed to gather ESG data from the Sustainability Section of company webpages on Yahoo! Finance. ##Descripted Statistics ##Ungrouped Statistics for Balance Sheets\n\nprint(balance_sheet.describe())\n\n       Ordinary Shares Number  ...  General Partnership Capital\ncount            2.658000e+03  ...                          5.0\nmean             6.405716e+08  ...                   -2000000.0\nstd              1.296627e+09  ...                          0.0\nmin              3.167625e+06  ...                   -2000000.0\n25%              1.420809e+08  ...                   -2000000.0\n50%              2.720531e+08  ...                   -2000000.0\n75%              5.952015e+08  ...                   -2000000.0\nmax              1.572341e+10  ...                   -2000000.0\n\n[8 rows x 142 columns]"
  },
  {
    "objectID": "project.html#y-finance-stats-ungrouped",
    "href": "project.html#y-finance-stats-ungrouped",
    "title": "DANL Project",
    "section": "1.1 Y-finance stats ungrouped",
    "text": "1.1 Y-finance stats ungrouped\n\nprint(stock_data.describe())\n\n                Open           High  ...  Dividends  Stock Splits\ncount  197796.000000  197796.000000  ...   197796.0      197796.0\nmean      150.803107     152.401419  ...        0.0           0.0\nstd       330.044562     333.614939  ...        0.0           0.0\nmin         1.030000       1.060000  ...        0.0           0.0\n25%        40.990002      41.439999  ...        0.0           0.0\n50%        83.540001      84.449997  ...        0.0           0.0\n75%       157.000000     158.509995  ...        0.0           0.0\nmax      8022.919922    8158.990234  ...        0.0           0.0\n\n[8 rows x 7 columns]"
  },
  {
    "objectID": "project.html#esg-stats-ungrouped",
    "href": "project.html#esg-stats-ungrouped",
    "title": "DANL Project",
    "section": "2.1 ESG stats ungrouped",
    "text": "2.1 ESG stats ungrouped\n\nprint(esg_proj_data.describe())\n\n       Total ESG Risk Score  ...  Controversy Level\ncount            114.000000  ...          100.00000\nmean              20.834211  ...            1.95000\nstd                6.922962  ...            0.79614\nmin                8.000000  ...            1.00000\n25%               16.225000  ...            1.00000\n50%               21.100000  ...            2.00000\n75%               24.425000  ...            2.00000\nmax               39.600000  ...            4.00000\n\n[8 rows x 5 columns]"
  },
  {
    "objectID": "project.html#heatmap",
    "href": "project.html#heatmap",
    "title": "DANL Project",
    "section": "3.1 Heatmap",
    "text": "3.1 Heatmap\n\nnumeric_data = esg_proj_data.select_dtypes(include='number')\ncorr_matrix = numeric_data.corr()\nplt.figure(figsize=(8, 6))\n\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n\n\nplt.title('Correlation Heatmap with Varied Correlations')\n\n\nplt.show()"
  },
  {
    "objectID": "project.html#question-1",
    "href": "project.html#question-1",
    "title": "DANL Project",
    "section": "3.2 Question 1",
    "text": "3.2 Question 1\nWhat is the distribution of closing prices for each company?\n\n#stock_data = pd.read_csv('yfinance-history.csv')\n\n# Convert 'Date' column to datetime format\n#stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n\n# Filter data for the last year\n#one_year_ago = pd.Timestamp.now() - pd.DateOffset(years=1)\n#filtered_data = stock_data[stock_data['Date'] &gt;= one_year_ago]\n\n# Plot histogram for each company's closing prices\n#plt.figure(figsize=(12, 8))\n#sns.histplot(data=filtered_data, x='Close', hue='ticker_symbol', bins=20, kde=True)\n#plt.title('Distribution of Closing Prices for Each Company Over the Last Year')\n#plt.xlabel('Closing Price')\n#plt.ylabel('Frequency')\n#plt.legend(title='Company')\n#plt.show()\n\nThe graph reveals insights into the variability and central tendency of closing prices across different companies. Companies with narrower and taller peaks in their histograms exhibit closing prices concentrated around specific values, indicating less variability. Conversely, broader and flatter histograms suggest a wider range of closing prices and greater variability in stock performance."
  },
  {
    "objectID": "project.html#question-2",
    "href": "project.html#question-2",
    "title": "DANL Project",
    "section": "3.3 Question 2",
    "text": "3.3 Question 2\nWhats the distribution of ESG score? And Which factor of ESG tends to cause the most risk?\n\ndef plot_distributions(df, title_prefix):\n    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n        plt.figure(figsize=(10, 6))\n        sns.histplot(df[col].dropna(), bins=20, kde=True)\n        plt.title(f'Distribution of {title_prefix} {col}')\n        plt.xlabel(col)\n        plt.ylabel('Frequency')\n        plt.show()\n   \n\n# Plot distributions for ESG data\nplot_distributions(esg_proj_data, 'ESG Data')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy visually inspecting the histograms, we can understand the distribution of ESG scores. The Environmental aspect of ESG causes companys the most risk."
  },
  {
    "objectID": "project.html#question-3",
    "href": "project.html#question-3",
    "title": "DANL Project",
    "section": "3.4 Question 3",
    "text": "3.4 Question 3\nWhich companies how the worst controversy level?\n\ntop_10_companies = esg_proj_data.sort_values(by='Total ESG Risk Score', ascending=False).head(10)\n\nprint(top_10_companies)\n\n                             Comapny Name  ...  Controversy Level\n64                The Boeing Company (BA)  ...                4.0\n44                  APA Corporation (APA)  ...                2.0\n48      Antero Resources Corporation (AR)  ...                1.0\n102                Caterpillar Inc. (CAT)  ...                4.0\n53         Atmos Energy Corporation (ATO)  ...                2.0\n78                   Bunge Global SA (BG)  ...                3.0\n52                     Ashland Inc. (ASH)  ...                2.0\n12   Archer-Daniels-Midland Company (ADM)  ...                3.0\n79     Bausch Health Companies Inc. (BHC)  ...                3.0\n100            Conagra Brands, Inc. (CAG)  ...                2.0\n\n[10 rows x 6 columns]\n\n\nCompanies with the worst controversy level are companies that deal with heavy machinery. For example, Boeing and Caterpillar Inc., both have a controversy level of a 4.0 and are the worst out of the top ten companies. Boeing, which builds airplanes, and Caterpillar, which build cranes and other machinery, both fall into the same category. ## Question 4\nHow do the successful companies compare in terms of ESG Risk Score and Controversy Level?\n\ndf = (esg_proj_data\n       .sort_values(['Total ESG Risk Score', 'Controversy Level'])\n       [[\"Comapny Name\", 'Comapny Name', 'Total ESG Risk Score', 'Controversy Level']]\n       .drop_duplicates(subset = 'Comapny Name')\n       )\n\ndf\n\n                          Comapny Name  ... Controversy Level\n105            CBRE Group, Inc. (CBRE)  ...               1.0\n56                   Avnet, Inc. (AVT)  ...               2.0\n111              CDW Corporation (CDW)  ...               NaN\n51       Arrow Electronics, Inc. (ARW)  ...               NaN\n54   AvalonBay Communities, Inc. (AVB)  ...               1.0\n..                                 ...  ...               ...\n102             Caterpillar Inc. (CAT)  ...               4.0\n48   Antero Resources Corporation (AR)  ...               1.0\n44               APA Corporation (APA)  ...               2.0\n64             The Boeing Company (BA)  ...               4.0\n114                                NaN  ...               NaN\n\n[115 rows x 4 columns]\n\n\nInsight on Correlation Among Stock Close, ESG Risk Score, and Controversy Level\nThe heatmap analysis surprisingly reveals minimal correlation among a company‚Äôs stock Close value, ESG Risk Score, and Controversy Level. However, the strongest correlation is found between the ESG Risk Score and Controversy Level. This highlights the close link between sustainability metrics and controversies, suggesting that investors focused on ethical considerations should prioritize ESG ratings and associated controversies when making investment decisions.\n\nHeatmap = esg_proj_data[[ 'Total ESG Risk Score', 'Controversy Level']].corr()\n\nplt.figure(figsize=(8, 6))\n\n#sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n\n# Title of the heatmap\nplt.title('Correlation Heatmap with Varied Correlations')\n\n# Display the heatmap\nplt.show()"
  },
  {
    "objectID": "project.html#conclusion",
    "href": "project.html#conclusion",
    "title": "DANL Project",
    "section": "3.5 Conclusion",
    "text": "3.5 Conclusion\nIn this project, we conducted an analysis focusing on stock prices, Environmental, Social, and Governance (ESG) scores, controversy levels, and their correlations. Here‚Äôs a concise summary of our findings:\nClosing Prices Distribution:\nHistograms revealed variability in closing prices across companies. Narrow peaks indicate less variability, while broader ones suggest greater variability.\nESG Scores Distribution:\nThe Environmental aspect of ESG posed the most risk, as seen in the score distribution.\nCompanies with Worst Controversy Level:\nHeavy machinery companies like Boeing and Caterpillar Inc.¬†had the highest controversy levels, hinting at industry-specific trends.\nComparison of Successful Companies in ESG:\nSuccessful companies showed varying ESG risk and controversy levels, emphasizing the need for sustainability in investment decisions.\nInsight on Correlation:\nWhile stock prices showed minimal correlation with ESG factors, a strong link was observed between ESG risk scores and controversy levels.\nConclusion:\nConsidering ESG factors alongside financial metrics is crucial for investors, as sustainability and controversies can significantly impact long-term performance. This analysis provides valuable insights for ethical investment decisions, highlighting the importance of integrating sustainability considerations into financial analysis. ## References\nCollaboraters:Owen Ellick, Dylan Thody\nChatGPT Helped with errors and code\nyahoo finance: https://finance.yahoo.com/"
  },
  {
    "objectID": "200_project.html",
    "href": "200_project.html",
    "title": "DANL Project",
    "section": "",
    "text": "##1 Introduction\nAbout this project üëè Welcome to our project, where we dive into the dynamic world of professional basketball through the lens of salaries and performance statisics. We will analyize a dataset with NBA player salaries and stats from the 2022-2023 season."
  },
  {
    "objectID": "200_project.html#data",
    "href": "200_project.html#data",
    "title": "DANL Project",
    "section": "0.1 2 Data",
    "text": "0.1 2 Data\nThe data.frame NBAsal contains a data from the 2022-2023 NBA season. It contains player per-game and advanced statistics for that season with player salary data. This allows us to create a comprehensive resource for understanding the performance and financial aspects of professional basketball players."
  },
  {
    "objectID": "200_project.html#conclusion",
    "href": "200_project.html#conclusion",
    "title": "DANL Project",
    "section": "5.1 Conclusion üèÖüèÄüëü",
    "text": "5.1 Conclusion üèÖüèÄüëü\n-Our exploration of NBA player salaries and performance unveiled key insights, emphasizing the pivotal role of scoring in determining player value.\n-Efficient players like Zion Williamson and Kevin Durant, with high field goal percentages, stood out.\n-Analyzing minutes played and turnovers for the top 10 players highlighted patterns, revealing challenges for primary ball handlers and consistency among players like Devin Booker and Donovan Mitchell."
  },
  {
    "objectID": "Danl_210_project.html",
    "href": "Danl_210_project.html",
    "title": "DANL Project",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nbalance_sheet = pd.read_csv('yfinance-balance-sheet.csv')\nstock_data = pd.read_csv('yfinance-history.csv')\nesg_proj_data = pd.read_csv('esg_proj_data.csv')"
  },
  {
    "objectID": "Danl_210_project.html#introduction",
    "href": "Danl_210_project.html#introduction",
    "title": "DANL Project",
    "section": "0.2 1 Introduction",
    "text": "0.2 1 Introduction\nESG(Environmental, Social, and Governance) factors are increasingly being considered by investors for making informed investment decisions. Understanding the relationship between ESG metrics and financial performance can provide valuable insights into a company‚Äôs sustainability and long-term viability.\nThis project aims to analyze the relationship between ESG metrics and financial/accounting data to identify any correlations and trends that may exist. By doing so, we seek to provide investors with a better understanding of how ESG factors impact financial performance and assist them in making more sustainable investment decisions.\nThe project utilizes Python scripts to collect financial, accounting, and ESG data. The financial and accounting data is obtained using the yfinance library, while Selenium is employed to gather ESG data from the Sustainability Section of company webpages on Yahoo! Finance. ##Descripted Statistics ##Ungrouped Statistics for Balance Sheets\n\nprint(balance_sheet.describe())\n\n       Ordinary Shares Number  Share Issued      Net Debt    Total Debt  \\\ncount            2.658000e+03  2.658000e+03  2.317000e+03  2.626000e+03   \nmean             6.405716e+08  7.568339e+08  1.291833e+10  1.922311e+10   \nstd              1.296627e+09  1.442190e+09  2.240450e+10  4.221775e+10   \nmin              3.167625e+06  9.589239e+06  2.200000e+07  1.404000e+06   \n25%              1.420809e+08  1.716074e+08  2.174900e+09  3.349737e+09   \n50%              2.720531e+08  3.142580e+08  5.714136e+09  7.261294e+09   \n75%              5.952015e+08  7.113500e+08  1.322700e+10  1.758525e+10   \nmax              1.572341e+10  1.572341e+10  2.238890e+11  4.421400e+11   \n\n       Tangible Book Value  Invested Capital  Working Capital  \\\ncount         2.659000e+03      2.658000e+03     2.314000e+03   \nmean          6.140413e+09      3.453963e+10     1.977094e+09   \nstd           2.906924e+10      6.710119e+10     7.778440e+09   \nmin          -9.834700e+10      1.221960e+08    -4.443000e+10   \n25%          -1.823000e+09      7.054684e+09    -2.506682e+08   \n50%           2.157460e+09      1.482450e+10     9.074155e+08   \n75%           8.880100e+09      3.350450e+10     2.709800e+09   \nmax           2.636610e+11      7.488770e+11     9.313100e+10   \n\n       Net Tangible Assets  Capital Lease Obligations  Common Stock Equity  \\\ncount         2.659000e+03               1.651000e+03         2.659000e+03   \nmean          6.475658e+09               1.730649e+09         1.661968e+10   \nstd           3.034589e+10               5.731350e+09         3.221102e+10   \nmin          -9.834700e+10              -6.100000e+07        -1.723300e+10   \n25%          -1.827950e+09               1.591580e+08         3.229000e+09   \n50%           2.120019e+09               3.918690e+08         7.500000e+09   \n75%           9.090150e+09               1.001500e+09         1.753100e+10   \nmax           2.722630e+11               7.729700e+10         3.067370e+11   \n\n       ...  Trading Securities  Investmentsin Subsidiariesat Cost  \\\ncount  ...        1.060000e+02                       3.600000e+01   \nmean   ...        8.437230e+10                       2.777855e+09   \nstd    ...        1.371783e+11                       3.849279e+09   \nmin    ...        0.000000e+00                       0.000000e+00   \n25%    ...        6.462450e+07                       4.755000e+08   \n50%    ...        1.174500e+09                       1.388500e+09   \n75%    ...        1.357220e+11                       1.962875e+09   \nmax    ...        5.742130e+11                       1.228100e+10   \n\n       Total Partnership Capital  Limited Partnership Capital  \\\ncount               1.000000e+01                 1.000000e+01   \nmean                1.964380e+10                 1.963130e+10   \nstd                 1.568801e+10                 1.567458e+10   \nmin                 4.479000e+09                 4.479000e+09   \n25%                 4.826250e+09                 4.826250e+09   \n50%                 1.910150e+10                 1.908800e+10   \n75%                 3.345025e+10                 3.343100e+10   \nmax                 3.668200e+10                 3.665600e+10   \n\n       Dueto Related Parties Non Current  Duefrom Related Parties Non Current  \\\ncount                       1.400000e+01                         1.100000e+01   \nmean                        9.710000e+08                         1.903109e+07   \nstd                         8.538153e+08                         4.242806e+07   \nmin                         5.000000e+06                         0.000000e+00   \n25%                         2.992500e+08                         0.000000e+00   \n50%                         6.075000e+08                         1.805000e+06   \n75%                         1.882750e+09                         3.529500e+06   \nmax                         2.376000e+09                         1.350000e+08   \n\n       Fixed Assets Revaluation Reserve  Current Deferred Taxes Liabilities  \\\ncount                      3.000000e+00                        2.000000e+00   \nmean                       3.001667e+09                        9.285000e+07   \nstd                        5.158336e+09                        9.192388e+05   \nmin                        2.300000e+07                        9.220000e+07   \n25%                        2.350000e+07                        9.252500e+07   \n50%                        2.400000e+07                        9.285000e+07   \n75%                        4.491000e+09                        9.317500e+07   \nmax                        8.958000e+09                        9.350000e+07   \n\n       Current Deferred Taxes Assets  General Partnership Capital  \ncount                   5.000000e+00                          5.0  \nmean                    3.234000e+08                   -2000000.0  \nstd                     6.618761e+07                          0.0  \nmin                     2.550000e+08                   -2000000.0  \n25%                     2.820000e+08                   -2000000.0  \n50%                     3.100000e+08                   -2000000.0  \n75%                     3.440000e+08                   -2000000.0  \nmax                     4.260000e+08                   -2000000.0  \n\n[8 rows x 142 columns]"
  },
  {
    "objectID": "Danl_210_project.html#y-finance-stats-ungrouped",
    "href": "Danl_210_project.html#y-finance-stats-ungrouped",
    "title": "DANL Project",
    "section": "1.1 Y-finance stats ungrouped",
    "text": "1.1 Y-finance stats ungrouped\n\nprint(stock_data.describe())\n\n                Open           High            Low          Close  \\\ncount  197796.000000  197796.000000  197796.000000  197796.000000   \nmean      150.803107     152.401419     149.302798     150.909848   \nstd       330.044562     333.614939     327.009474     330.419589   \nmin         1.030000       1.060000       0.780000       0.980000   \n25%        40.990002      41.439999      40.509998      41.000000   \n50%        83.540001      84.449997      82.610001      83.599998   \n75%       157.000000     158.509995     155.539993     157.052502   \nmax      8022.919922    8158.990234    8010.000000    8099.959961   \n\n             Volume  Dividends  Stock Splits  \ncount  1.977960e+05   197796.0      197796.0  \nmean   4.134482e+06        0.0           0.0  \nstd    9.289442e+06        0.0           0.0  \nmin    0.000000e+00        0.0           0.0  \n25%    8.323000e+05        0.0           0.0  \n50%    1.707600e+06        0.0           0.0  \n75%    3.854425e+06        0.0           0.0  \nmax    3.160112e+08        0.0           0.0"
  },
  {
    "objectID": "Danl_210_project.html#esg-stats-ungrouped",
    "href": "Danl_210_project.html#esg-stats-ungrouped",
    "title": "DANL Project",
    "section": "2.1 ESG stats ungrouped",
    "text": "2.1 ESG stats ungrouped\n\nprint(esg_proj_data.describe())\n\n       Total ESG Risk Score  Environmental Risk Score  Social Risk Score  \\\ncount            114.000000                111.000000         111.000000   \nmean              20.834211                  4.845045           8.748649   \nstd                6.922962                  4.819237           4.165221   \nmin                8.000000                  0.100000           0.800000   \n25%               16.225000                  1.500000           5.950000   \n50%               21.100000                  2.500000           8.900000   \n75%               24.425000                  7.350000          10.850000   \nmax               39.600000                 22.000000          22.500000   \n\n       Governance Risk Score  Controversy Level  \ncount             111.000000          100.00000  \nmean                7.133333            1.95000  \nstd                 2.562078            0.79614  \nmin                 3.100000            1.00000  \n25%                 5.050000            1.00000  \n50%                 6.600000            2.00000  \n75%                 8.950000            2.00000  \nmax                13.700000            4.00000"
  },
  {
    "objectID": "Danl_210_project.html#heatmap",
    "href": "Danl_210_project.html#heatmap",
    "title": "DANL Project",
    "section": "3.1 Heatmap",
    "text": "3.1 Heatmap\n\nnumeric_data = esg_proj_data.select_dtypes(include='number')\ncorr_matrix = numeric_data.corr()\nplt.figure(figsize=(8, 6))\n\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n\n\nplt.title('Correlation Heatmap with Varied Correlations')\n\n\nplt.show()"
  },
  {
    "objectID": "Danl_210_project.html#question-1",
    "href": "Danl_210_project.html#question-1",
    "title": "DANL Project",
    "section": "3.2 Question 1",
    "text": "3.2 Question 1\nWhat is the distribution of closing prices for each company?\n\n#stock_data = pd.read_csv('yfinance-history.csv')\n\n# Convert 'Date' column to datetime format\n#stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n\n# Filter data for the last year\n#one_year_ago = pd.Timestamp.now() - pd.DateOffset(years=1)\n#filtered_data = stock_data[stock_data['Date'] &gt;= one_year_ago]\n\n# Plot histogram for each company's closing prices\n#plt.figure(figsize=(12, 8))\n#sns.histplot(data=filtered_data, x='Close', h\n#hue='ticker_symbol', bins=20, kde=True)\n#plt.title('Distribution of Closing Prices for Each Company Over the Last Year')\n#plt.xlabel('Closing Price')\n#plt.ylabel('Frequency')\n#plt.legend(title='Company')\n#plt.show()\n\n#This block was having render issues hence the #\n\nThe graph reveals insights into the variability and central tendency of closing prices across different companies. Companies with narrower and taller peaks in their histograms exhibit closing prices concentrated around specific values, indicating less variability. Conversely, broader and flatter histograms suggest a wider range of closing prices and greater variability in stock performance."
  },
  {
    "objectID": "Danl_210_project.html#question-2",
    "href": "Danl_210_project.html#question-2",
    "title": "DANL Project",
    "section": "3.3 Question 2",
    "text": "3.3 Question 2\nWhats the distribution of ESG score? And Which factor of ESG tends to cause the most risk?\n\ndef plot_distributions(df, title_prefix):\n    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n        plt.figure(figsize=(10, 6))\n        sns.histplot(df[col].dropna(), bins=20, kde=True)\n        plt.title(f'Distribution of {title_prefix} {col}')\n        plt.xlabel(col)\n        plt.ylabel('Frequency')\n        plt.show()\n   \n\n# Plot distributions for ESG data\nplot_distributions(esg_proj_data, 'ESG Data')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy visually inspecting the histograms, we can understand the distribution of ESG scores. The Environmental aspect of ESG causes companys the most risk."
  },
  {
    "objectID": "Danl_210_project.html#question-3",
    "href": "Danl_210_project.html#question-3",
    "title": "DANL Project",
    "section": "3.4 Question 3",
    "text": "3.4 Question 3\nWhich companies how the worst controversy level?\n\ntop_10_companies = esg_proj_data.sort_values(by='Total ESG Risk Score', ascending=False).head(10)\n\nprint(top_10_companies)\n\n                             Comapny Name  Total ESG Risk Score  \\\n64                The Boeing Company (BA)                  39.6   \n44                  APA Corporation (APA)                  38.8   \n48      Antero Resources Corporation (AR)                  36.4   \n102                Caterpillar Inc. (CAT)                  36.2   \n53         Atmos Energy Corporation (ATO)                  34.6   \n78                   Bunge Global SA (BG)                  32.9   \n52                     Ashland Inc. (ASH)                  32.4   \n12   Archer-Daniels-Midland Company (ADM)                  31.8   \n79     Bausch Health Companies Inc. (BHC)                  31.4   \n100            Conagra Brands, Inc. (CAG)                  30.8   \n\n     Environmental Risk Score  Social Risk Score  Governance Risk Score  \\\n64                        8.8               22.5                    8.3   \n44                       22.0                8.9                    8.0   \n48                        NaN                NaN                    NaN   \n102                      10.4               17.7                    8.1   \n53                       14.8               13.4                    6.4   \n78                       14.4               13.3                    5.3   \n52                       19.0                7.2                    6.2   \n12                       16.6               10.1                    5.0   \n79                        5.3               17.9                    8.1   \n100                      10.7               15.4                    4.7   \n\n     Controversy Level  \n64                 4.0  \n44                 2.0  \n48                 1.0  \n102                4.0  \n53                 2.0  \n78                 3.0  \n52                 2.0  \n12                 3.0  \n79                 3.0  \n100                2.0  \n\n\nCompanies with the worst controversy level are companies that deal with heavy machinery. For example, Boeing and Caterpillar Inc., both have a controversy level of a 4.0 and are the worst out of the top ten companies. Boeing, which builds airplanes, and Caterpillar, which build cranes and other machinery, both fall into the same category. ## Question 4\nHow do the successful companies compare in terms of ESG Risk Score and Controversy Level?\n\ndf = (esg_proj_data\n       .sort_values(['Total ESG Risk Score', 'Controversy Level'])\n       [[\"Comapny Name\", 'Comapny Name', 'Total ESG Risk Score', 'Controversy Level']]\n       .drop_duplicates(subset = 'Comapny Name')\n       )\n\ndf\n\n\n\n\n\n\n\n\nComapny Name\nComapny Name\nTotal ESG Risk Score\nControversy Level\n\n\n\n\n105\nCBRE Group, Inc. (CBRE)\nCBRE Group, Inc. (CBRE)\n8.0\n1.0\n\n\n56\nAvnet, Inc. (AVT)\nAvnet, Inc. (AVT)\n8.2\n2.0\n\n\n111\nCDW Corporation (CDW)\nCDW Corporation (CDW)\n9.2\nNaN\n\n\n51\nArrow Electronics, Inc. (ARW)\nArrow Electronics, Inc. (ARW)\n9.4\nNaN\n\n\n54\nAvalonBay Communities, Inc. (AVB)\nAvalonBay Communities, Inc. (AVB)\n9.8\n1.0\n\n\n...\n...\n...\n...\n...\n\n\n102\nCaterpillar Inc. (CAT)\nCaterpillar Inc. (CAT)\n36.2\n4.0\n\n\n48\nAntero Resources Corporation (AR)\nAntero Resources Corporation (AR)\n36.4\n1.0\n\n\n44\nAPA Corporation (APA)\nAPA Corporation (APA)\n38.8\n2.0\n\n\n64\nThe Boeing Company (BA)\nThe Boeing Company (BA)\n39.6\n4.0\n\n\n114\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n115 rows √ó 4 columns\n\n\n\nInsight on Correlation Among Stock Close, ESG Risk Score, and Controversy Level\nThe heatmap analysis surprisingly reveals minimal correlation among a company‚Äôs stock Close value, ESG Risk Score, and Controversy Level. However, the strongest correlation is found between the ESG Risk Score and Controversy Level. This highlights the close link between sustainability metrics and controversies, suggesting that investors focused on ethical considerations should prioritize ESG ratings and associated controversies when making investment decisions.\n\nHeatmap = esg_proj_data[[ 'Total ESG Risk Score', 'Controversy Level']].corr()\n\nplt.figure(figsize=(8, 6))\n\n#sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n\n# Title of the heatmap\nplt.title('Correlation Heatmap with Varied Correlations')\n\n# Display the heatmap\nplt.show()"
  },
  {
    "objectID": "Danl_210_project.html#conclusion",
    "href": "Danl_210_project.html#conclusion",
    "title": "DANL Project",
    "section": "3.5 Conclusion",
    "text": "3.5 Conclusion\nIn this project, we conducted an analysis focusing on stock prices, Environmental, Social, and Governance (ESG) scores, controversy levels, and their correlations. Here‚Äôs a concise summary of our findings:\nClosing Prices Distribution:\nHistograms revealed variability in closing prices across companies. Narrow peaks indicate less variability, while broader ones suggest greater variability.\nESG Scores Distribution:\nThe Environmental aspect of ESG posed the most risk, as seen in the score distribution.\nCompanies with Worst Controversy Level:\nHeavy machinery companies like Boeing and Caterpillar Inc.¬†had the highest controversy levels, hinting at industry-specific trends.\nComparison of Successful Companies in ESG:\nSuccessful companies showed varying ESG risk and controversy levels, emphasizing the need for sustainability in investment decisions.\nInsight on Correlation:\nWhile stock prices showed minimal correlation with ESG factors, a strong link was observed between ESG risk scores and controversy levels.\nConclusion:\nConsidering ESG factors alongside financial metrics is crucial for investors, as sustainability and controversies can significantly impact long-term performance. This analysis provides valuable insights for ethical investment decisions, highlighting the importance of integrating sustainability considerations into financial analysis. ## References\nCollaboraters:Owen Ellick, Dylan Thody\nChatGPT Helped with errors and code\nyahoo finance: https://finance.yahoo.com/"
  },
  {
    "objectID": "writeup.html#introduction",
    "href": "writeup.html#introduction",
    "title": "Shooting for Success: Analyzing NBA Player Performance and Value üèÄ",
    "section": "Introduction",
    "text": "Introduction\n\nBackground üíª\nBasketball is a data-rich sport where player performance directly impacts team success. Understanding key statistics can help teams make better decisions about player value, game strategy, and resource allocation. This project dives into the 2022-23 NBA player dataset to uncover insights that could influence team building and player development.\n\n\nStatement of the Project Interest\nThe goal of this project is to analyze the relationship between player performance metrics (offensive and defensive) and their salaries. We aim to identify what stats correlate most with high salaries and whether there are undervalued players based on their contributions."
  },
  {
    "objectID": "writeup.html#data-storytelling",
    "href": "writeup.html#data-storytelling",
    "title": "Shooting for Success: Analyzing NBA Player Performance and Value üèÄ",
    "section": "Data Storytelling üìñ",
    "text": "Data Storytelling üìñ\n\nQuestions and Objectives\n\nWhat performance metrics are most strongly correlated with player salaries?\nAre there any undervalued players based on performance statistics?\nHow do offensive and defensive metrics compare in their influence on salary?\nWhat patterns emerge among players with high Player Efficiency Ratings (PER) and Win Shares (WS)?\nHow does a player‚Äôs. scoring efficiency (True Shooting Percentage) compare to their salary?\n\n\n\n\nData Transformation and Descriptive Statistics\nTo prepare the data and highlight key takeaways, we performed the following steps:\n\nData Cleaning\n\n# Load necessary libraries\nlibrary(tidyverse)\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.4     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Load the NBA dataset\nnba_players &lt;- read_csv(\"http://bcdanl.github.io/data/nba_players.csv\")\n\nRows: 467 Columns: 51\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr  (3): PlayerName, Position, Team\ndbl (48): Salary, Age, GP, GS, MP, FG, FGA, FG_pct, 3P, 3PA, 3P_pct, 2P, 2PA...\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Data cleaning: Remove outliers and invalid entries\nnba_players_clean &lt;- nba_players %&gt;%\n  filter(!is.na(Salary) & Salary &gt; 0 & GP &gt; 10) %&gt;%  # Remove players with missing or zero salary, and low game participation\n  mutate(Salary_Millions = Salary / 1e6)  # Convert salary to millions for easier readability\n\nFindings: This cleaning ensures our analysis focuses on active players with meaningful contributions, avoiding noise from incomplete or irrelevant data points.\n\n\n\nKey Summary Statistics\nThe following code calculates averages for key metrics like salary, points per game (PTS), Player Efficiency Rating (PER), and Win Shares (WS).\n\n# Calculate key descriptive statistics\nsummary_stats &lt;- nba_players_clean %&gt;%\n  summarize(\n    avg_salary = mean(Salary_Millions),\n    median_salary = median(Salary_Millions),\n    avg_pts = mean(PTS),\n    avg_per = mean(PER),\n    avg_ws = mean(WS)\n  )\n\nprint(summary_stats)\n\n# A tibble: 1 √ó 5\n  avg_salary median_salary avg_pts avg_per avg_ws\n       &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1       9.55          4.63    9.96    13.7   2.69\n\n\nFindings: The calculated averages provide a baseline for comparing individual players. For example: - Average salary: $9.55 million - Average points per game: 9.96 points\nThese values help identify outliers and standout players.\n\n\n\nCorrelation Analysis\nThis code computes the correlation matrix to explore relationships between salary and performance metrics. Higher correlations indicate stronger relationships.\n\n# Compute correlations between salary and performance metrics\ncorrelation_matrix &lt;- nba_players_clean %&gt;%\n  select(Salary_Millions, PER, WS, TS_pct, PTS, AST, STL, BLK) %&gt;%\n  cor()\nprint(correlation_matrix)\n\n                Salary_Millions       PER        WS     TS_pct       PTS\nSalary_Millions       1.0000000 0.5456509 0.5970353 0.20168943 0.7292814\nPER                   0.5456509 1.0000000 0.7409330 0.63499002 0.7011657\nWS                    0.5970353 0.7409330 1.0000000 0.51919903 0.7221934\nTS_pct                0.2016894 0.6349900 0.5191990 1.00000000 0.2745762\nPTS                   0.7292814 0.7011657 0.7221934 0.27457624 1.0000000\nAST                   0.6161033 0.4725905 0.5426286 0.04748020 0.7325362\nSTL                   0.4874090 0.4118194 0.5429013 0.09145927 0.6069206\nBLK                   0.2743947 0.4826649 0.4754230 0.38408129 0.2574327\n                       AST        STL        BLK\nSalary_Millions 0.61610328 0.48740903 0.27439469\nPER             0.47259052 0.41181939 0.48266485\nWS              0.54262859 0.54290135 0.47542296\nTS_pct          0.04748020 0.09145927 0.38408129\nPTS             0.73253620 0.60692061 0.25743267\nAST             1.00000000 0.68220450 0.02631061\nSTL             0.68220450 1.00000000 0.15878444\nBLK             0.02631061 0.15878444 1.00000000\n\n\nFindings: Metrics like PTS, AST, PER, and WS are likely to show strong correlations with salary, suggesting they are key indicators of player value.\n\n\n\n\nData Visualization\n\nSalary Distribution\nThis histogram shows how player salaries are distributed across the league, emphasizing the disparities between top earners and the rest.\n\nlibrary(ggplot2)\n\n# Histogram of salary distribution\nsalary_plot &lt;- ggplot(nba_players_clean, aes(x = Salary_Millions)) +\n  geom_histogram(binwidth = 5, fill = \"blue\", color = \"white\", alpha = 0.7) +\n  labs(title = \"Distribution of NBA Player Salaries (in Millions)\",\n       x = \"Salary (in Millions)\",\n       y = \"Number of Players\") +\n  scale_x_continuous(breaks = seq(0, max(nba_players_clean$Salary_Millions), by = 5)) +\n  theme_minimal()\n\nprint(salary_plot)\n\n\n\n\n\n\n\n\nFindings: Most players earn less than $10 million per season, with a few outliers earning significantly more.\n\n\n\n\nCorrelation Heatmap\nThis heatmap visualizes the strength of relationships between salary and various performance metrics.\n\nlibrary(ggcorrplot)\n\nheatmap_plot &lt;- ggcorrplot(correlation_matrix, \n                           lab = TRUE, \n                           lab_size = 5,\n                           colors = c(\"red\", \"white\", \"blue\"),\n                           title = \"Correlation Between Salary and Performance Metrics\")\n\nheatmap_plot + \n  theme_minimal(base_size = 14) +\n  theme(aspect.ratio = 1,\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n\n\n\n\n\n\n\n\nFindings: Strong correlations between salary and metrics like PTS PER, WS, and AST suggest these are key drivers of player compensation.\n\n\n\nScatterplot of Salary vs.¬†PER\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nscatter_salary_per &lt;- ggplot(nba_players_clean, aes(x = PER, y = Salary_Millions, color = PER)) +\n  geom_point(alpha = 0.7, size = 3) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\", linetype = \"dashed\") +\n  scale_color_gradient(low = \"lightblue\", high = \"darkgreen\") +\n  labs(\n    title = \"Salary vs. Player Efficiency Rating (PER)\",\n    x = \"Player Efficiency Rating (PER)\",\n    y = \"Salary (in Millions)\",\n    color = \"PER\"\n  ) +\n  scale_y_continuous(labels = dollar_format(prefix = \"$\", suffix = \"M\")) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.title.x = element_text(face = \"bold\"),\n    axis.title.y = element_text(face = \"bold\")\n  )\n\nprint(scatter_salary_per)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFindings: Some players are shown with high PER have relatively low salaries, highlighting potential undervalued players. This means that they are highly efficient yet are paid lower than they deserve.\n\n\n\nTop 10 Players by Win Shares ‚õπÔ∏è‚Äç‚ôÇÔ∏è\nThis bar chart compares the Win Shares (WS) of the top 10 players with their corresponding salaries.\n\n# Identify top 10 players by Win Shares\ntop_players_ws &lt;- nba_players_clean %&gt;%\n  arrange(desc(WS)) %&gt;%\n  slice(1:10) %&gt;% \n  relocate(WS, .after = Salary)\nprint(top_players_ws)\n\n# A tibble: 10 √ó 52\n   PlayerName    Salary    WS Position   Age Team     GP    GS    MP    FG   FGA\n   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Domantas Sab‚Ä¶ 2.11e7  12.6 C           26 SAC      79    79  34.6   7.3  11.9\n 2 Jimmy Butler  3.77e7  12.3 PF          33 MIA      64    64  33.4   7.5  13.9\n 3 Joel Embiid   3.36e7  12.3 C           28 PHI      66    66  34.6  11    20.1\n 4 Shai Gilgeou‚Ä¶ 3.09e7  11.4 PG          24 OKC      68    68  35.5  10.4  20.3\n 5 Jayson Tatum  3.04e7  10.5 SF          24 BOS      74    74  36.9   9.8  21.1\n 6 Jarrett Allen 2   e7   9.5 C           24 CLE      68    68  32.6   5.9   9.2\n 7 Damian Lilla‚Ä¶ 4.25e7   9   PG          32 POR      58    58  36.3   9.6  20.7\n 8 Anthony Davis 3.80e7   9   C           29 LAL      56    54  34     9.7  17.2\n 9 Donovan Mitc‚Ä¶ 3.09e7   8.9 SG          26 CLE      68    68  35.8  10    20.6\n10 Jalen Brunson 2.77e7   8.7 PG          26 NYK      68    68  35     8.6  17.6\n# ‚Ñπ 41 more variables: FG_pct &lt;dbl&gt;, `3P` &lt;dbl&gt;, `3PA` &lt;dbl&gt;, `3P_pct` &lt;dbl&gt;,\n#   `2P` &lt;dbl&gt;, `2PA` &lt;dbl&gt;, `2P_pct` &lt;dbl&gt;, eFG_pct &lt;dbl&gt;, FT &lt;dbl&gt;,\n#   FTA &lt;dbl&gt;, FT_pct &lt;dbl&gt;, ORB &lt;dbl&gt;, DRB &lt;dbl&gt;, TRB &lt;dbl&gt;, AST &lt;dbl&gt;,\n#   STL &lt;dbl&gt;, BLK &lt;dbl&gt;, TOV &lt;dbl&gt;, PF &lt;dbl&gt;, PTS &lt;dbl&gt;, TotalMinutes &lt;dbl&gt;,\n#   PER &lt;dbl&gt;, TS_pct &lt;dbl&gt;, `3PAr` &lt;dbl&gt;, FTr &lt;dbl&gt;, ORB_pct &lt;dbl&gt;,\n#   DRB_pct &lt;dbl&gt;, TRB_pct &lt;dbl&gt;, AST_pct &lt;dbl&gt;, STL_pct &lt;dbl&gt;, BLK_pct &lt;dbl&gt;,\n#   TOV_pct &lt;dbl&gt;, USG_pct &lt;dbl&gt;, OWS &lt;dbl&gt;, DWS &lt;dbl&gt;, WS_per_48 &lt;dbl&gt;, ‚Ä¶\n\n\n\nlibrary(ggplot2)\nlibrary(viridis)  # for prettier color gradients\n\nWarning: package 'viridis' was built under R version 4.2.3\n\n\nLoading required package: viridisLite\n\n\n\nAttaching package: 'viridis'\n\n\nThe following object is masked from 'package:scales':\n\n    viridis_pal\n\nlibrary(ggthemes) # optional, for additional theme options\n\nWarning: package 'ggthemes' was built under R version 4.2.3\n\n# Enhanced bar chart\nbar_top_ws &lt;- ggplot(top_players_ws, aes(x = reorder(PlayerName, WS), y = WS, fill = Salary_Millions)) +\n  geom_bar(stat = \"identity\", color = \"black\", width = 0.7) +\n  coord_flip() +\n  geom_text(aes(label = round(WS, 1)), hjust = -0.2, size = 4, fontface = \"bold\") +  # Add data labels\n  scale_fill_viridis(option = \"plasma\", direction = -1, name = \"Salary ($M)\", guide = guide_colorbar(barwidth = 10, barheight = 8)) +\n  labs(\n    title = \"Top 10 NBA Players by Win Shares\",\n    subtitle = \"Colored by Salary (in Millions)\",\n    x = \"Player Name\",\n    y = \"Win Shares\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16),\n    plot.subtitle = element_text(face = \"italic\", size = 12),\n    axis.title.x = element_text(face = \"bold\", size = 13),\n    axis.title.y = element_text(face = \"bold\", size = 13),\n    axis.text = element_text(size = 11),\n    legend.title = element_text(face = \"bold\"),\n    legend.position = \"right\"\n  ) +\n  ylim(0, max(top_players_ws$WS) + 2)  # Add space for text labels\n\nprint(bar_top_ws)\n\n\n\n\n\n\n\n\nFindings: The highest-performing players (by WS) tend to have high salaries, although there are a few exceptions. For example, Domantas Sabonis is the number one NBA player by win share, but his salary is the second lowest among top 10 players by win share. Jarret Allen is another example he is 6th in the NBA in win share yet he is being paid the lowest by any of the top 10 players by win share. This tells us that Sabonis and Allen are extremely undervalued and contribute to their teams winning percentage at a lower price compared to others in the NBA.\n\n\n\nOffensive vs.¬†Defensive Metrics and Salary üìà\nBelow is a chart showing the Offensive and Defensive Metrics for the top 10 highest paid NBA players. The goal is to see which performance metrics (offensive or defensive) contribute to a players salary more.\n\nlibrary(tidyverse)\n\n# Prepare data\nnba_off_def &lt;- nba_players_clean %&gt;%\n  slice_max(Salary_Millions, n = 10) %&gt;%   # Top 10 highest-paid players\n  select(PlayerName, PTS, AST, STL, BLK) %&gt;%\n  pivot_longer(cols = c(PTS, AST, STL, BLK),\n               names_to = \"Metric\",\n               values_to = \"Value\")\n\n# Create grouped bar chart\ngrouped_bar_chart &lt;- ggplot(nba_off_def, aes(x = reorder(PlayerName, -Value), y = Value, fill = Metric)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.8), width = 0.7, color = \"black\", alpha = 0.9) +\n  labs(title = \"Top 10 Highest-Paid Players: *Offensive vs. Defensive Metrics*\",\n       subtitle = \"Comparing Points, Assists, Steals, and Blocks for Each Player\",\n       x = \"Player Name\",\n       y = \"Metric Value\",\n       fill = \"Metric\") +\n  scale_fill_manual(values = c(\"PTS\" = \"#1f77b4\", \"AST\" = \"#2ca02c\", \n                               \"STL\" = \"#ff7f0e\", \"BLK\" = \"#9467bd\")) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold.italic\", size = 15, hjust = 0.5),\n    plot.subtitle = element_text(face = \"italic\", size = 14, hjust = 0.5, margin = margin(b = 10)),\n    axis.title.x = element_text(face = \"bold\", size = 13, margin = margin(t = 10)),\n    axis.title.y = element_text(face = \"bold\", size = 13, margin = margin(r = 10)),\n    axis.text.x = element_text(angle = 45, hjust = 1, face = \"bold\"),\n    axis.text.y = element_text(face = \"bold\"),\n    legend.title = element_text(face = \"bold\"),\n    legend.position = \"right\",\n    panel.grid.major.y = element_line(color = \"grey80\"),\n    panel.grid.minor = element_blank()\n  ) +\n  guides(fill = guide_legend(title.position = \"top\", title.hjust = 0.5))\n\nprint(grouped_bar_chart)\n\n\n\n\n\n\n\n\nFindings 1. Offesive Metrics Dominate (PTS and AST)\n\nPoints (PTS): The PTS (light blue bars) are significantly higher for all players compared to other metrics. This suggests that scoring ability is a major factor contributing to high salaries.\n\nFor example, Giannis Antetokounmpo, Stephen Curry, and Damian Lillard have extremely high PTS values, indicating their scoring dominance.\nPlayers like Kevin Durant and Lebron James also exhibit high PTS, reinforcing the importance of offensive capabilities.\n\nAssists (AST): The AST (green bars) are the second-highest metric for most players, especially for those known as playmakers, such as LeBron James, Russell Westbrook, and Stephen Curry. This indicates that playmaking ability is another key factor in high salaries.\n\n\nDefensive Metrics Are Less Prominent (BLK and STL)\n\n\nBlocks (BLK): The BLK (purple bars) are relatively low for all players, even for those known for their defensive prowess, like Kawhi Leonard and Giannis Antetokounmpo. This suggests that blocking is not a significant determinant of salary for these top players.\nSteals (STL): The STL (orange bars) are also consistently low across all players, indicating that steals, like blocks, have less influence on salary when compared to offensive metrics.\n\n\nBalanced Players Are More Valued\n\n\nSome players demonstrate a balance between offensive (PTS and AST) and defensive (STL and BLK) metrics. For example:\n\nGiannis Antetokounmpo and LeBron James show relatively higher values in both offensive and defensive categories, making them versatile players.\nKawhi Leonard shows moderate contributions in all metrics, aligning with his reputation as a two-way player.\n\n\n\nOutliers in Specific Metrics\n\n\nStephen Curry: Has the highest PTS value but relatively lower defensive metrics, emphasizing his role as a scoring specialist.\nRussell Westbrook: Shows higher AST values compared to most other players, highlighting his playmaking ability.\n\nKey Conclusions:\n\nOffensive contributions (PTS and AST) have a stronger influence on salary than defensive contributions (BLK and STL).\n\nPlayers who excel in scoring (e.g., Curry, Durant, James) or playmaking (e.g., Westbrook, James) are more highly compensated.\n\nDefensive metrics, while still important are less impactful on salary for these top players, due to the heightened difficulty to achieve higher defensive statistics although balanced players like Giannis and LeBron are exceptions.\n\nThis analysis ties the metrics back to salary by showing that offensive capabilities are the primary drivers of high compensation. - In the NBA, while being a great defensive player is important, todays fast paced, high scoring game favors players who can score a lot of points, hence the top 10 paid players all having high offensive statistics.\n\n\n\nInteractive Scatterplot of Salary vs.¬†True Shooting Percentage (TS%) üìä\n\n# Load required libraries\nlibrary(tidyverse)\nlibrary(plotly)\n\nWarning: package 'plotly' was built under R version 4.2.3\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n# Set a minimum threshold for total minutes played\nmin_minutes &lt;- 1000\n\n# Filter dataset to include players with at least 'min_minutes'\nfiltered_nba_data &lt;- nba_players_clean %&gt;%\n  filter(TotalMinutes &gt;= min_minutes)  # Replace 'TotalMinutes' with your actual column name\n\n# Scatterplot: Salary vs. True Shooting Percentage (TS%)\nscatter_salary_ts &lt;- ggplot(filtered_nba_data, aes(\n  x = TS_pct, y = Salary_Millions, \n  text = paste(\n    \"&lt;b&gt;Player:&lt;/b&gt;\", PlayerName, \n    \"&lt;br&gt;&lt;b&gt;TS%:&lt;/b&gt;\", scales::percent(TS_pct, accuracy = 0.1),\n    \"&lt;br&gt;&lt;b&gt;Salary:&lt;/b&gt;\", scales::dollar(Salary_Millions, prefix = \"$\", suffix = \"M\"),\n    \"&lt;br&gt;&lt;b&gt;Total Minutes Played:&lt;/b&gt;\", TotalMinutes\n  )\n)) +\n  geom_point(color = \"#1f78b4\", alpha = 0.8, size = 2) +  # Blue points with transparency\n  geom_smooth(method = \"lm\", se = FALSE, color = \"#ff7f00\", size = 1.2) +  # Orange trend line\n  labs(\n    title = \"Interactive Scatterplot: Salary vs. True Shooting Percentage (TS%)\",\n    subtitle = paste(\"Players with at least\", min_minutes, \"Total Minutes Played\"),\n    x = \"True Shooting Percentage (TS%)\",\n    y = \"Salary (in Millions)\"\n  ) +\n  scale_x_continuous(\n    labels = scales::percent_format(), \n    limits = c(0.45, 0.75),\n    breaks = seq(0.45, 0.75, by = .05), # Assuming TS% ranges between 40% and 70%\n    expand = c(0, 0)\n  ) +\n  scale_y_continuous(\n    labels = scales::dollar_format(prefix = \"$\", suffix = \"M\"), \n    limits = c(0, 50),  # Assuming salary ranges up to $50M\n    expand = c(0, 0)\n  ) +\n  theme_minimal(base_size = 14, base_family = \"Arial\") +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    plot.subtitle = element_text(face = \"italic\", size = 12, hjust = 0.5, color = \"gray40\"),\n    axis.title.x = element_text(face = \"italic\", size = 12),\n    axis.title.y = element_text(face = \"italic\", size = 12),\n    axis.text = element_text(size = 10),\n    panel.grid.major = element_line(color = \"gray80\", size = 0.5),\n    panel.grid.minor = element_blank(),\n    legend.position = \"none\"\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\n‚Ñπ Please use the `linewidth` argument instead.\n\n# Convert the ggplot object to an interactive plot\ninteractive_scatter_salary_ts &lt;- ggplotly(\n  scatter_salary_ts, \n  tooltip = \"text\"  # Display the custom tooltip text\n)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n# Save the interactive plot as an HTML file\nhtmlwidgets::saveWidget(\n  interactive_scatter_salary_ts, \n  \"interactive_scatter_salary_ts_filtered_minutes.html\", \n  selfcontained = TRUE\n)\n\n# Print the interactive plot to view in RStudio\ninteractive_scatter_salary_ts\n\n\n\n\n\nAbove is an interactive plot showing the relationship between True Shooting Percentage and Player Salaries."
  },
  {
    "objectID": "writeup.html#significance-of-the-project",
    "href": "writeup.html#significance-of-the-project",
    "title": "Shooting for Success: Analyzing NBA Player Performance and Value üèÄ",
    "section": "Significance of the Project üîä",
    "text": "Significance of the Project üîä\n\nWhy These Findings Matter\nThe insights uncovered in this project go beyond basketball and can be applied to several real-world scenarios:\n\nInfluencing Business Decisions in Sports:\n\nSalary Optimization: Teams can use the findings to identify undervalued players whose contributions (e.g., high PER or WS) exceed their current salaries. This can guide better salary negotiations and resource allocation.\nPlayer Evaluation: By understanding which metrics (e.g., offensive contributions like PTS and AST) strongly influence salaries, teams can refine their scouting and recruitment strategies to focus on high-impact players.\nData-Driven Contracts: Teams can use this analysis to structure contracts that better reflect a player‚Äôs overall value, balancing offensive and defensive contributions.\n\nBroader Applications Beyond Sports:\n\nWorkforce Compensation Analysis: Just as we analyzed player salaries, organizations in other industries can use data to ensure fair and performance-based compensation for employees.\nInfluencing Public Policy: The methodology of linking measurable performance metrics to pay could also be applied in sectors like education, healthcare, and public services to assess resource allocation and equity.\n\nEnhancing Fan Engagement:\n\nFans love debating whether players are underpaid or overpaid. This analysis provides a data-backed framework for fans, sports journalists, and commentators to discuss player value and team-building strategies.\n\n\n\n\nConnecting to Broader Themes\n\nData-Driven Decision-Making: This project underscores how data can lead to more informed, fair, and efficient decisions in any industry.\nValue Assessment: By identifying inefficiencies and patterns in compensation, we can promote better allocation of resources, whether in sports or other fields."
  },
  {
    "objectID": "writeup.html#references",
    "href": "writeup.html#references",
    "title": "Shooting for Success: Analyzing NBA Player Performance and Value üèÄ",
    "section": "References",
    "text": "References\n\nData Sources\n\nNBA Dataset: Source\n\nContains player performance metrics and salary data for the 2022-23 NBA season.\n\n\n\n\nAI Assistance\nThis project benefited from the use of GitHub Copilot, a code-generation and AI assistant tool.\nGitHub Copilot was employed to:\n\nRefine code aesthetics, such as improving themes, scales, and formatting for better presentation.\nProvide insights and guidance on implementing project-specific requirements (e.g., filtering datasets, embedding interactive visualizations).\nAnswer technical questions and suggest best practices for reproducible and professional code.\nHelp to refine errors and troubleshoot incorrect code.\n\nGitHub Copilot facilitated faster implementation and enhanced the overall quality of the project by offering suggestions and reducing development time.\nNote: All outputs from GitHub Copilot were reviewed and validated by the project team to ensure accuracy and relevance to the project goals."
  },
  {
    "objectID": "Danl_310_HW2_Starkey_Jake.html",
    "href": "Danl_310_HW2_Starkey_Jake.html",
    "title": "Danl_310_HW2_Starkey_Jake.qmd",
    "section": "",
    "text": "##Q1\nlibrary(tidyverse)\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.4     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(ggrepel)\n\nWarning: package 'ggrepel' was built under R version 4.2.3\n\nlibrary(readr)\n\nhdi_corruption &lt;- read_csv(\n  'https://bcdanl.github.io/data/hdi_corruption.csv')\n\nRows: 704 Columns: 5\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): country, region\ndbl (3): year, cpi, hdi\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nselected_countries &lt;- c(\"Argentina\", \"China\", \"Egypt\", \"Senegal\", \"South Africa\", \"Greece\", \"United States\", \"Germany\", \"Singapore\", \"Norway\")\n\nhdi_corruption_labeled &lt;- hdi_corruption %&gt;% \n  filter(country %in% selected_countries) %&gt;% \n  distinct(country, .keep_all = TRUE)\n\nx_label &lt;- \"Corruption Perceptions Index, 2014 (100 = least corrupt)\"\ny_label &lt;- \"Human Development Index, 2014 (1.0 = most developed)\"\n\n\nggplot(data = hdi_corruption,\n       mapping = \n         aes(x = cpi, \n             y = hdi, \n             color = region)) +\n  labs(x = x_label,\n       y = y_label) +\n  \n  \n  geom_point(alpha = .5) +\n  geom_smooth(method = \"lm\", formula = y ~ log(x), se = FALSE, color = \"blue\") +\n  geom_text_repel(data = hdi_corruption_labeled, aes(label = country), color = \"black\", size = 3, max.overlaps = Inf, segment.color = \"black\", box.padding = .75, point.padding = .75)  +\n  theme(legend.position = \"top\")\n\nWarning: Removed 102 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 102 rows containing missing values (`geom_point()`).\n##Q2\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggrepel)\nlibrary(hrbrthemes) \n\nNOTE: Either Arial Narrow or Roboto Condensed fonts are required to use these themes.\n\n\n      Please use hrbrthemes::import_roboto_condensed() to install Roboto Condensed and\n\n\n      if Arial Narrow is not on your system, please see https://bit.ly/arialnarrow\n\nlabor_data &lt;- read_csv('/Users/jakestarkey/Downloads/labor_supply.csv')\n\nRows: 7038907 Columns: 5\n\n\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\ndbl (5): YEAR, ASECWT, SEX, LABFORCE, NCHLT5\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncivilian_population &lt;- labor_data %&gt;% filter(LABFORCE != 0)\n\n\nlabor_force_data &lt;- civilian_population %&gt;% \n  arrange(YEAR, SEX, NCHLT5) %&gt;% \n  group_by(YEAR, SEX, NCHLT5) %&gt;% \n  summarize(civilian_pop = sum(ASECWT), labor_force_pop = sum(ASECWT[LABFORCE == 2])) %&gt;% \n  mutate(participation_rate =(labor_force_pop / civilian_pop) * 100)\n\n`summarise()` has grouped output by 'YEAR', 'SEX'. You can override using the\n`.groups` argument.\n\nlabor_force_data$SEX &lt;- factor(labor_force_data$SEX, levels = c(1, 2), labels = c(\"Male\", \"Female\"))\nlabor_force_data$NCHLT5 &lt;- factor(labor_force_data$NCHLT5, levels = c(1, 0), labels = c(\"Having Children Under Age 5 in Household\",\"No Child Under Age 5 in Household\"))\n\nlabor_force_data &lt;- labor_force_data %&gt;% filter(!is.na(NCHLT5))\nggplot(labor_force_data, aes(x = YEAR, y = participation_rate, color = SEX)) +\n  geom_line(linewidth = 1) +\n  facet_wrap(~ NCHLT5, ncol = 2) +\n  labs(\n    title = \"Fertility and Labor Supply in the U.S.\\n1982-2022\",\n    x = \"Year\",\n    y = \"Labor Force Participation Rate\",\n    color = \"\"\n  ) +\n  scale_y_continuous(labels = function(x) paste0(x, \"%\"), limits = c(50, 100), breaks = seq(50, 100, 10)) +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(hjust = 0, size = 12), \n    axis.title = element_text(size = 10), \n    axis.text = element_text(size = 8), \n    panel.grid.minor = element_blank(),\n    plot.margin = margin(10, 10, 10, 10), \n    strip.text = element_text(size = 9) \n  ) +\n  geom_label_repel(\n    data = labor_force_data %&gt;% filter(YEAR == max(YEAR)),\n    aes(label = SEX),\n    nudge_x = 2,\n    direction = \"y\",\n    hjust = -0.1,\n    segment.size = 0.2,\n    size = 3 \n  ) +\n  annotate(\"text\", x = 2000, y = 45, label = \"Data: IPUMS-CPS, University of Minnesota, www.ipums.org.\", size = 2.5) # Adjust annotate size\n\nWarning: Removed 2 rows containing missing values (`geom_text()`).\n\n\nWarning: ggrepel: 71 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\nWarning: ggrepel: 74 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps"
  },
  {
    "objectID": "Danl_310_HW2_Starkey_Jake.html#question-3",
    "href": "Danl_310_HW2_Starkey_Jake.html#question-3",
    "title": "Danl_310_HW2_Starkey_Jake.qmd",
    "section": "Question 3",
    "text": "Question 3\n\nstarbucks &lt;- read.csv(\n  'https://bcdanl.github.io/data/starbucks.csv')\n\n\nQ3a.\n\nAdd the following two variables to starbucks data.frame\ncaffeine_mgml: Caffeine in milligrams per mL\ncalories_kcml: Calories KCal per mL\n\n\nlibrary(readr)\nlibrary(dplyr)\nstarbucks &lt;- starbucks %&gt;%\n  mutate(\n    caffeine_mgml = caffeine_mg / serv_size_m_l,\n    calories_kcml = calories / serv_size_m_l\n  )\n\nhead(starbucks)\n\n                            product_name   size milk whip serv_size_m_l\n1             brewed coffee - dark roast  short    0    0           236\n2             brewed coffee - dark roast   tall    0    0           354\n3             brewed coffee - dark roast grande    0    0           473\n4             brewed coffee - dark roast  venti    0    0           591\n5 brewed coffee - decaf pike place roast  short    0    0           236\n6 brewed coffee - decaf pike place roast   tall    0    0           354\n  calories total_fat_g saturated_fat_g trans_fat_g cholesterol_mg sodium_mg\n1        3         0.1               0           0              0         5\n2        4         0.1               0           0              0        10\n3        5         0.1               0           0              0        10\n4        5         0.1               0           0              0        10\n5        3         0.1               0           0              0         5\n6        4         0.1               0           0              0        10\n  total_carbs_g fiber_g sugar_g caffeine_mg caffeine_mgml calories_kcml\n1             0       0       0         130    0.55084746   0.012711864\n2             0       0       0         193    0.54519774   0.011299435\n3             0       0       0         260    0.54968288   0.010570825\n4             0       0       0         340    0.57529611   0.008460237\n5             0       0       0          15    0.06355932   0.012711864\n6             0       0       0          20    0.05649718   0.011299435\n\n\n\n\nQ3b.\n\nCalculate a mean caffeine_mgml and a mean calories_kcml for each product name\n\n\nproduct_means &lt;- starbucks %&gt;%\n  group_by(product_name) %&gt;%\n  summarize(\n    mean_caffeine_mgml = mean(caffeine_mgml, na.rm = TRUE),\n    mean_calories_kcml = mean(calories_kcml, na.rm = TRUE)\n  )\n\nprint(product_means)\n\n# A tibble: 87 √ó 3\n   product_name                      mean_caffeine_mgml mean_calories_kcml\n   &lt;chr&gt;                                          &lt;dbl&gt;              &lt;dbl&gt;\n 1 Blended Strawberry Lemonade                    0                  0.423\n 2 Caff√® Latte                                    0.261              0.360\n 3 Caff√® Misto                                    0.322              0.197\n 4 Caff√® Mocha                                    0.333              0.673\n 5 Caff√® Vanilla Frappuccino Blended              0.187              0.692\n 6 Caff√® Vanilla Frappuccino Light                0.187              0.383\n 7 Cappuccino                                     0.275              0.256\n 8 Caramel Apple Spice                            0                  0.711\n 9 Caramel Frappuccino Blended                    0.198              0.656\n10 Caramel Frappuccino Light                      0.181              0.294\n# ‚Ñπ 77 more rows\n\n\n\n\nQ3c.\n\nPlotting\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(ggrepel)\nlibrary(showtext)\n\nWarning: package 'showtext' was built under R version 4.2.3\n\n\nLoading required package: sysfonts\n\n\nWarning: package 'sysfonts' was built under R version 4.2.3\n\n\nLoading required package: showtextdb\n\nlibrary(ggtext)\nshowtext_auto()\nfont_add_google(\"Annie Use Your Telescope\", \"annie\")\n\ntop_caffeine_df &lt;- product_means %&gt;%\n  arrange(desc(mean_caffeine_mgml)) %&gt;%\n  head(10)\n\n# Get top 10 products by calories per ml\ntop_calories_df &lt;- product_means %&gt;%\n  arrange(desc(mean_calories_kcml)) %&gt;%\n  head(10)\n\ntop_products &lt;- product_means %&gt;%\n  filter(product_name %in% c(top_caffeine_df$product_name, top_calories_df$product_name))\n\n\n\nggplot(top_products, aes(x = mean_calories_kcml, y = mean_caffeine_mgml)) +\n  geom_hline(yintercept = seq(0, 0.8, by = 0.2), color = \"lightgray\") +\n  geom_vline(xintercept = seq(0, 0.8, by = 0.2), color = \"lightgray\") +\n  geom_point(aes(color = product_name), size = 3) +\n  geom_text_repel(\n    aes(label = product_name, color = product_name),\n    max.overlaps = 30,\n    size = 2.5,\n    min.segment.length = 0,\n    point.padding = 0.3,  \n    box.padding = 0.3,    \n    show.legend = FALSE,\n    family = \"annie\"\n  )  +\n  annotate(\n    \"richtext\",\n    x = 0.8,             \n    y = 0.65,             \n    label = \"&lt;img src='https://bcdanl.github.io/lec_figs/starbucks.png' width='70'/&gt;\", \n    fill = NA,\n    size = 0,          \n    color = NA\n  )  +\n  annotate(\n    \"rect\",\n    xmin = 0.01, xmax = 0.34, ymin = 0.42, ymax = 0.8,\n    alpha = .5, fill = \"gray\"\n  )  +\n  annotate(\n    \"rect\",\n    xmin = 0.68, xmax = .9, ymin = 0, ymax = 0.34,\n    alpha = .5, fill = \"gray\"\n  ) +\n  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 0.95, by = 0.2)) +\n  scale_y_continuous(limits = c(-0.05, 0.85), breaks = seq(0, 0.8, by = 0.2)) +\n  labs(\n    title = \"STARBUCKS DRINKS\",\n    subtitle = \"Caffeine or Calories, which one you would go?\",\n    x = expression(\"Calories (Kcal mL\"^-1*\")\"),\n    y = expression(\"Caffeine (mg mL\"^-1*\")\"),\n    caption = \"Source: Starbucks Coffee Company Beverage Nutrition Information\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(color = \"#00704A\", face = \"bold\", size = 22),\n    plot.subtitle = element_text(size = 14),\n    legend.position = \"none\",\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    axis.title = element_text(size = 12)\n  )"
  },
  {
    "objectID": "Danl_310_Hw1_Starkey_Jake.html",
    "href": "Danl_310_Hw1_Starkey_Jake.html",
    "title": "HW_1",
    "section": "",
    "text": "#Q1\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nncdc_temp &lt;- read_csv(\"https://bcdanl.github.io/data/ncdc_temp_cleaned.csv\")\n\nRows: 1464 Columns: 7\n\n\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr  (4): station_id, month, flag, location\ndbl  (2): day, temperature\ndate (1): date\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nncdc_temp$month &lt;- factor(ncdc_temp$month, levels = sprintf(\"%02d\", 1:12), \n                          labels = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \n                                     \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"))\n\nmonthly_avg_temp &lt;- ncdc_temp %&gt;%\n  group_by(month, location) %&gt;%\n  summarise(avg_temp = mean(temperature, na.rm = TRUE))\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\nfiltered_points &lt;- monthly_avg_temp %&gt;% filter(month %in% c(\"Jan\", \"Apr\", \"Jul\", \"Oct\"))\n\nggplot(monthly_avg_temp, aes(x = month, y = avg_temp, color = location, group = location)) +\n  geom_line(size = 1) + \n  geom_point(data = filtered_points, aes(x = month, y = avg_temp), size = 0.5, color = \"black\") + \n  scale_x_discrete(breaks = c(\"Jan\", \"Apr\", \"Jul\", \"Oct\"), labels = c(\"Jan\", \"Apr\", \"Jul\", \"Oct\")) + \n  labs(x = \"Month\", y = \"Temperature (¬∞F)\", title = \"Monthly Average Temperature by Location\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n#Q2\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî lubridate 1.9.4     ‚úî tibble    3.2.1\n‚úî purrr     1.0.2     ‚úî tidyr     1.3.0\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nncdc_temp &lt;- read_csv(\n 'https://bcdanl.github.io/data/ncdc_temp_cleaned.csv')\n\nRows: 1464 Columns: 7\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr  (4): station_id, month, flag, location\ndbl  (2): day, temperature\ndate (1): date\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nncdc_temp$month &lt;- factor(ncdc_temp$month, levels = sprintf(\"%02d\", 1:12))\n\n\nggplot(ncdc_temp, aes(x = month, y = temperature)) +  \n  geom_boxplot(fill = \"lightgray\", color = \"black\") +  \n  scale_y_continuous(breaks = seq(40, 100, 20), limits = c(20, 100)) +\n  labs(\n    title = \"\",\n    x = \"month\",\n    y = \"mean temperature (¬∞F)\"  \n  ) +\n  theme_bw() +\n  theme(\n    panel.grid.major.y = element_line(color = \"lightgray\", linetype = \"dotted\"),\n    panel.grid.minor = element_blank(),\n    panel.border = element_blank(),\n    axis.ticks.x = element_line(color = \"black\"),\n    axis.ticks.length.x = unit(0.2, \"cm\"),\n    text = element_text(size = 11)\n  )\n\nWarning: Removed 47 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n#Q3\nlibrary(tidyverse)\nlibrary(ggridges)\n\nWarning: package 'ggridges' was built under R version 4.2.3\n\nncdc_temp &lt;- read_csv(\n 'https://bcdanl.github.io/data/ncdc_temp_cleaned.csv')\n\nRows: 1464 Columns: 7\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr  (4): station_id, month, flag, location\ndbl  (2): day, temperature\ndate (1): date\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmonthly_mean_temp &lt;- ncdc_temp %&gt;% \n  group_by(month) %&gt;% \n  summarise(mean_temp = mean(temperature, na.rm = TRUE))\n\nggplot(ncdc_temp, aes(x = temperature, y = factor(month))) +\n  geom_density_ridges(scale = 2, fill = 'lightblue', linetype = \"blank\") +\n  labs(x = \"mean temperature (¬∞F)\", y = \"month\") +\n  theme_minimal()\n\nPicking joint bandwidth of 3.12\n\n\n\n\n\n\n\n\n\n\n#Q4\nlibrary(ggplot2)\ndata(mtcars)\n\nggplot(mtcars, aes(x = disp, y = mpg, color = hp)) +\n  geom_point() +\n  scale_color_gradient(low = \"navy\", high = \"lightblue\") +\n  labs(x = \"displacement(cu. in.)\", y = \"fuel efficiency(mpg)\", color = \"hp\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n#Q5\nlibrary(tidyverse)\n\npopgrowth_df &lt;- read_csv(\n  'https://bcdanl.github.io/data/popgrowth.csv')\n\nRows: 51 Columns: 7\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): region, division, state\ndbl (4): pop2000, pop2010, popgrowth, area\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npopgrowth_df &lt;- popgrowth_df %&gt;% \n  mutate(popgrowth = (pop2010 - pop2000) / pop2000 * 100)\n\nggplot(popgrowth_df, aes(x = reorder(state,popgrowth), y = popgrowth, fill = region)) + \n  geom_col() +\n  coord_flip() +\n  scale_y_continuous(labels = scales::percent_format(scale = 1)) +\n  labs( x = \" reorder(state, popgrowth)\", y = \"population growth, 2000 to 2010\", fill = \"region\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n#Q6\nlibrary(tidyverse)\nmale_Aus &lt;- read_csv(\n  'https://bcdanl.github.io/data/aus_athletics_male.csv')\n\nRows: 83 Columns: 13\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr  (2): sex, sport\ndbl (11): rcc, wcc, hc, hg, ferr, bmi, ssf, pcBfat, lbm, height, weight\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nggplot(male_Aus, aes (x = height, y = pcBfat, shape = sport, color = sport)) +\n  geom_point(size = 3, alpha = 0.7) +\n  scale_shape_manual( values = c( \"basketball\" = 16, \"field\" = 15, \"swimming\" = 18, \"track\" = 17, \"water polo\" = 25)) +\n  scale_color_manual(values = c(\"basketball\" = \"darkred\", \"field\" = \"grey\", \"swimming\" = \"grey\", \"track\" = \"grey\", \"water polo\" = \"grey\")) +\n  labs(x = \"height(cm)\", y = \"% body fat\", shape = \"sport\", color = \"sport\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n#Q7\n\ntitanic &lt;- read_csv(\n  'https://bcdanl.github.io/data/titanic_cleaned.csv')\n\nRows: 756 Columns: 4\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): class, gender\ndbl (1): age\nlgl (1): survived\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntitanic_female &lt;- titanic %&gt;% \n  mutate(gender = \"female\", gender_new = \"all passengers\")\n\ntitanic_male &lt;- titanic %&gt;% \n  mutate(gender = \"male\", gender_new = \"all     passengers\")\n\ntitanic_2x &lt;- titanic_male %&gt;% \n  rbind(titanic_female)\n\ntitanic &lt;- titanic %&gt;% \n  mutate(gender_new = gender)\n\n  ggplot(data = titanic,\n         aes(x = age, y = after_stat(count), fill = gender_new)) +\n  geom_density(data = titanic_2x, color = NA) +\n    geom_density(color = NA) +\n  facet_wrap(~gender) +\n    scale_fill_manual(values = c(\"all passengers\" = \"lightgray\", \"female\" = \"darkorange\", \"male\" = \"darkblue\"), labels = c(\"all passengers\", \"females\", \"males\")) +\n    theme_minimal() +\n    theme(legend.position = \"bottom\") +\n    labs(fill = \"\")\n\n\n\n\n\n\n\n\n\n#Q8\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(readr)\n\n\ncows_filtered &lt;- read_csv(\"https://bcdanl.github.io/data/cows_filtered.csv\")\n\nRows: 80 Columns: 3\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (2): age, breed\ndbl (1): butterfat\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nggplot(cows_filtered, aes(x = butterfat, fill = breed, color = breed)) +\n  geom_density(alpha = 0.3) +\n  labs(x = \"butterfat contents\", y = \"density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n#Q9\n#@s1arkey"
  },
  {
    "objectID": "Danl_210_project.html#analyzing-esg-and-financial-data-for-investment-decision-making",
    "href": "Danl_210_project.html#analyzing-esg-and-financial-data-for-investment-decision-making",
    "title": "DANL Project",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nbalance_sheet = pd.read_csv('yfinance-balance-sheet.csv')\nstock_data = pd.read_csv('yfinance-history.csv')\nesg_proj_data = pd.read_csv('esg_proj_data.csv')"
  },
  {
    "objectID": "project.html#analyzing-esg-and-financial-data-for-investment-decision-making",
    "href": "project.html#analyzing-esg-and-financial-data-for-investment-decision-making",
    "title": "DANL Project",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nbalance_sheet = pd.read_csv('yfinance-balance-sheet.csv')\nstock_data = pd.read_csv('yfinance-history.csv')\nesg_proj_data = pd.read_csv('esg_proj_data.csv')"
  },
  {
    "objectID": "index.html#intro",
    "href": "index.html#intro",
    "title": "Jake Starkey",
    "section": "",
    "text": "Thanks for tuning into my project!\nUnder the project tab, the code breaks down, ESG (Environmental, Social, and Governance) data highlighting the importance of integrating sustainability considerations into financial analysis.\nUnder the blog tab, You will find different homework projects from multiple classes.Favorite Artist, Python Basics, Spotify All, Restaurant, NFL 2022, and Beer Markets all break down data frames using variables to answer questions."
  },
  {
    "objectID": "posts/Python Basics /PythonBasics.html#variables-are-names-not-places",
    "href": "posts/Python Basics /PythonBasics.html#variables-are-names-not-places",
    "title": "Python Basics",
    "section": "",
    "text": "*A value is datum (literal) such as a number or text\n*There are different types of values:\n*352.3 is known as a float or double;\n*22 is an integer;\n*‚ÄúHello World!‚Äù is a string.\n\nlist_example =  [10, 1.23, \"like this\", True, None]\nprint(list_example)\ntype(list_example)\n\n[10, 1.23, 'like this', True, None]\n\n\nlist\n\n\n[10, 1.23, ‚Äòlike this‚Äô, True, None]\n*The most. basic built-in data types that we‚Äôll need to know about are: integers, 10 floats, 1.23 strings, ‚Äúlike this‚Äù booleans, True nothing, None\n*Python also has a built-in type of data container called a list (ex. [10,15,20]) that can contain anything, even different types\n##Values, Variables, and Types\n\na = 10\nprint(a)\n\n10\n\n\n*A variable is a name that refers to a value.\n**We can think of a variable as a box that has a value, or multiple values, packed inside it A variable is just a name!\n*Sometimes you will hear variables referred to as objects.\n*Everything that is not a literal value, such as 10, is an object\n##Assignment (=)\n\n# Here we assign the integer value 5 to the variable x.\nx = 5   \n\n# Now we can use the variable x in the next line.\ny = x + 12  \ny\n\n17\n\n\n*In Python, we use = to assign a value to a variable\n*In math, = means equality of both sides\n*In programs, = means assignment: assign the value on the right side to the variable on the left side.\n*In programming code, everything on the right side needs to have a value.\n*The right side can be a literal value, or a variable that has already been assigned a value, or a combination.\n*When Python reads y= x + 12, it does the following: Sees the = in the middle.Knows that this is an assignment.\n*Calculates the right side (gets the value of the object referred to by x and adds it to 12).\n*Assigns the result to the left-side variable, y.\n##Code and Comment Style\n*The two main principles for coding and managing data are: Make things easier for your future self. Don‚Äôt trust your future self.\n*The # mark is Google Colab‚Äôs comment character The # character has many names: hash, sharp, pound, or octothorpe. The # indicates that the rest of the line is to be ignored. **Write comments before the line that you want the comment to apply to.\n*Consider adding more comments on code cells and their results using text cells.\n##Brackets *There are several kinds of brackets in Python, including [], {}, and ().\n\nvector = ['a', 'b']\nvector[0]\n\n'a'\n\n\n*[] is used to denote a list or to signify accessing a position using an index\n\n{'a', 'b'}  # set\n{'first_letter': 'a', 'second_letter': 'b'}  # dictionary\n\n{'first_letter': 'a', 'second_letter': 'b'}\n\n\n{‚Äòfirst_letter‚Äô: ‚Äòa‚Äô, ‚Äòsecond_letter‚Äô: ‚Äòb‚Äô} {} is used to denote a set or a dictionary (with key-value pairs)\n*() is used to denote a tuple, or the arguments to a function, ex. function(x) where x is the input passed to the function ##Q1\n\n(2**5/(7*(4-2**3)))\n\n-1.1428571428571428\n\n\n##Q2\n\n20 == '20'\n\nFalse\n\n\n*This is saying 20 is not equal to ‚Äò20‚Äô because they are different data types (int vs string)\n\nx = 4.0\ny = .5\nz = 3*y - x\n\nx &lt; y or 3*y &lt; x\n\nTrue\n\n\nTrue This says the expression is true since 3.5 &lt; 4\n##Q3\n\nfare = \"$10.00\"\ntip = \"2.00$\"\ntax = \"$ 0.80\"\n\nWrite a Python code that uses slicing and the print() function to print out the following message:\nThe total trip cost is: $12.80\n\ntotal =fare = \"$10.00\"\ntip = \"2.00$\"\ntax = \"$ 0.80\"\ntotal = fare[0:2] + tip[0] + tax[3:6]\nprint(\"The total trip cost is:\", total)\n\n#The total trip cost is: $12.80The total trip cost is:\", total)\n\nThe total trip cost is: $12.80\n\n\n##Q4\n\nlist_variable = [100, 144, 169, 1000, 8]\n\nWrite a Python code that uses print() and max() functions to print out the largest value in the list, list_variable, as follows:\nThe largest value in the list is: 1000\n\nlist_variable = [100,144,169,1000,8]\nx =max(list_variable)\nprint('The largest value in the list is:',x)\n\n#The largest value in the list is: 1000\n\nThe largest value in the list is: 1000\n\n\nThe largest value in the list is: 1000 ##Q5 Import the pandas library as pd. Install the itables package. *From itables, import the function init_notebook_mode and show.\n\nimport pandas as pd\n!pip install itables\nfrom itables import init_notebook_mode\nfrom itables import show\n\nRequirement already satisfied: itables in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (1.6.3)\nRequirement already satisfied: IPython in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from itables) (8.15.0)\nRequirement already satisfied: pandas in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from itables) (2.0.3)\nRequirement already satisfied: numpy in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from itables) (1.24.3)\nRequirement already satisfied: backcall in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (0.2.0)\nRequirement already satisfied: decorator in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (5.1.1)\nRequirement already satisfied: jedi&gt;=0.16 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (0.18.1)\nRequirement already satisfied: matplotlib-inline in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (0.1.6)\nRequirement already satisfied: pickleshare in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.37,&lt;3.1.0,&gt;=3.0.30 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (3.0.36)\nRequirement already satisfied: pygments&gt;=2.4.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (2.15.1)\nRequirement already satisfied: stack-data in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (0.2.0)\nRequirement already satisfied: traitlets&gt;=5 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (5.7.1)\nRequirement already satisfied: pexpect&gt;4.3 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (4.8.0)\nRequirement already satisfied: appnope in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from IPython-&gt;itables) (0.1.2)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from pandas-&gt;itables) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from pandas-&gt;itables) (2023.3.post1)\nRequirement already satisfied: tzdata&gt;=2022.1 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from pandas-&gt;itables) (2023.3)\nRequirement already satisfied: parso&lt;0.9.0,&gt;=0.8.0 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from jedi&gt;=0.16-&gt;IPython-&gt;itables) (0.8.3)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from pexpect&gt;4.3-&gt;IPython-&gt;itables) (0.7.0)\nRequirement already satisfied: wcwidth in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,&lt;3.1.0,&gt;=3.0.30-&gt;IPython-&gt;itables) (0.2.5)\nRequirement already satisfied: six&gt;=1.5 in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;itables) (1.16.0)\nRequirement already satisfied: executing in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from stack-data-&gt;IPython-&gt;itables) (0.8.3)\nRequirement already satisfied: asttokens in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from stack-data-&gt;IPython-&gt;itables) (2.0.5)\nRequirement already satisfied: pure-eval in /Users/jakestarkey/anaconda3/lib/python3.11/site-packages (from stack-data-&gt;IPython-&gt;itables) (0.2.2)"
  },
  {
    "objectID": "posts/Beer Markets /beer-markets.html#question-1",
    "href": "posts/Beer Markets /beer-markets.html#question-1",
    "title": "Beer Markets",
    "section": "",
    "text": "For Question 1, run the following R command to read the beer market data.\n\nlibrary(tidyverse)\nlibrary(skimr)\n\n\nbeer_mkts &lt;- read.csv('https://bcdanl.github.io/data/beer_markets.csv')\n\n\nrmarkdown::paged_table(beer_mkts)\n\n\n  \n\n\n\n-Each observation in beer_mkts is a household-level transaction record for a purchase of beer."
  },
  {
    "objectID": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q1a",
    "href": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q1a",
    "title": "NFL 2022",
    "section": "",
    "text": "Provide a link for your Github repository ‚úÖ https://github.com/s1arkey/s1arkey.github.io\nAdd a URL for your website (https://YOUR_GITHUB_USERNAME.github.io/) in the About section in your GitHub repository webpage by clicking the setting. ‚úÖ\n\nSee about section in my GitHub repository webpage for answer\nLink to website https://s1arkey.github.io/"
  },
  {
    "objectID": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q1b",
    "href": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q1b",
    "title": "NFL 2022",
    "section": "",
    "text": "Make sure that your GitHub repository, named YOUR_GITHUB_USERNAME.github.io, is set to public. ‚úÖ\nUpdate your website at https://YOUR_GITHUB_USERNAME.github.io/index.html to:\n\nInclude links to (1) your LinkedIn page, (2) GitHub page (https://github.com/YOUR_GITHUB_USERNAME), and (3) a PDF file of your R√®sume (https://YOUR_GITHUB_USERNAME.github.io/YOUR_RESUME.pdf) ‚úÖ\nOffer a description of yourself, detailing your education background and professional experience. ‚úÖ\nDisplay your own profile picture with your face, not the one shown below. ‚úÖ"
  },
  {
    "objectID": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q1c",
    "href": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q1c",
    "title": "NFL 2022",
    "section": "",
    "text": "Change the title of your blog. ‚úÖ\n\nThat is, to replace Insightful Analytics with your own blog name.\n\nRemove the blog posts Post With Code, Starwars, and Beer Markets. ‚úÖ\nRevise the Welcome To My Blog post. ‚úÖ\nPost three different blog articles based on data analysis using the following three CSV files: ‚úÖ\n\nhttps://bcdanl.github.io/data/DOHMH_NYC_Restaurant_Inspection.csv\nhttps://bcdanl.github.io/data/spotify_all.csv\nhttps://bcdanl.github.io/data/beer_markets.csv\n\n\nMake sure that each blog post has categories and is associated with a proper image file that is displayed as a thumbnail at the list page of the blog. ‚úÖ\nMake sure that each blog post uses emojis properly. (E.g., üòÑ üç∫ üé∂ üçï) ‚úÖ\nMake sure that each blog post includes its thumbnail image and at least three ggplot figures. ‚úÖ\nYou can refer to the previous DANL 200 Homework Assignments and Exams for your blog posts.\n\n\n##Question 2. NFL in 2022 üèà\n\nAdd a blog post with your answers for Question 2 to your website (https://YOUR_GITHUB_USERNAME.github.io/).\n\nMake sure that your blog post for Question 2 includes all the questionnaires and your answers to them.\nMake sure that your blog post for Question 2 has a section for each sub-question (e.g., Q2a, Q2b) in Question 2, so that the Table of Contents display the section for each questionnaire.\n\nThe following is the data.frame for Question 2.\n\n\nNFL2022_stuffs &lt;- read.csv('https://bcdanl.github.io/data/NFL2022_stuffs.csv')\n\n\nNFL2022_stuffs is the data.frame that contains information about NFL games in year 2022, in which the unit of observation is a single play for each drive in a NFL game."
  },
  {
    "objectID": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#variable-description",
    "href": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#variable-description",
    "title": "NFL 2022",
    "section": "",
    "text": "play_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play\ngame_id: Ten digit identifier for NFL game.\ndrive: Numeric drive number in the game.\nweek: Season week.\nposteam: String abbreviation for the team with possession.\nqtr: Quarter of the game (5 is overtime).\nhalf_seconds_remaining: Numeric seconds remaining in the half.\ndown: The down for the given play.\n\nBasically you get four attempts (aka downs) to move the ball 10 yards (by either running with it or passing it).\nIf you make 10 yards then you get another set of four downs.\n\npass: Binary indicator if the play was a pass play.\nwp: Estimated winning probability for the posteam given the current situation at the start of the given play."
  },
  {
    "objectID": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2a",
    "href": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2a",
    "title": "NFL 2022",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.4     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(skimr)\n\nIn data.frame, NFL2022_stuffs, remove observations for which values of posteam is missing.\n\nq2a &lt;- NFL2022_stuffs %&gt;% \n  filter(!is.na(posteam))"
  },
  {
    "objectID": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2b",
    "href": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2b",
    "title": "NFL 2022",
    "section": "",
    "text": "Summarize the mean value of pass for each posteam when all the following conditions hold:\n\n\nwp is greater than 20% and less than 75%;\ndown is less than or equal to 2; and\nhalf_seconds_remaining is greater than 120.\n\n\nq2b &lt;- NFL2022_stuffs %&gt;% \n  filter(between(wp, 0.2, 0.75),\n         down &lt;= 2,\n         half_seconds_remaining &gt; 120)\n\nmeanvalq2b &lt;- q2b %&gt;% \n  group_by(posteam) %&gt;% \n  summarise(mean_pass = mean(pass, na.rm = TRUE))"
  },
  {
    "objectID": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2c",
    "href": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2c",
    "title": "NFL 2022",
    "section": "",
    "text": "Provide both (1) a ggplot code with geom_point() using the resulting data.frame in Q2b and (2) a simple comments to describe the mean value of pass for each posteam.\n\nIn the ggplot, reorder the posteam categories based on the mean value of pass in ascending or in descending order.\n\n\n\nmeanvaldesc &lt;- meanvalq2b %&gt;% \n  arrange(desc(mean_pass))\n\nggplot(meanvaldesc, aes(x = mean_pass, y = reorder(posteam, mean_pass))) +\n  geom_point()+\n  labs(x= \"Percentage of Pass Plays\",\n       y= \"Team with possesion\")\n\n\n\n\n\n\n\n\nComments:\n\nCincinnati, Kansas City, Los Angeles Chargers, Buffalo Bills, and Philadelphia eagles had the top 5 highest average percentage of pass plays during the 2022 season.\nAtlanta, Washington, Chicago, New Orleans, and Tennessee had the top 5 lowest average percentage of pass plays during the 2022 season."
  },
  {
    "objectID": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2d",
    "href": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2d",
    "title": "NFL 2022",
    "section": "",
    "text": "Consider the following data.frame, NFL2022_epa:\n\n\nNFL2022_epa &lt;- read.csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\n\nVariable description for NFL2022_epa\n\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play\ngame_id: Ten digit identifier for NFL game.\ndrive: Numeric drive number in the game.\nposteam: String abbreviation for the team with possession.\npasser: Name of the player who passed a ball to a receiver by initially taking a three-step drop and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks)\nreceiver: Name of the receiver.\nepa: Expected points added (EPA) by the posteam for the given play.\n\nCreate the data.frame, NFL2022_stuffs_EPA, that includes\n\nAll the variables in the data.frame, NFL2022_stuffs;\nThe variables, passer, receiver, and epa, from the data.frame, NFL2022_epa. by joining the two data.frames.\n\nIn the resulting data.frame, NFL2022_stuffs_EPA, remove observations with NA in passer.\n\nAnswer:\n\nNFL2022_stuffs_EPA &lt;- left_join(NFL2022_stuffs, NFL2022_epa, by = c(\"play_id\", \"game_id\", \"drive\", \"posteam\"))\n\nNFL2022_stuffs_EPA &lt;- NFL2022_stuffs_EPA %&gt;%\n  filter(!is.na(passer))"
  },
  {
    "objectID": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2e",
    "href": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2e",
    "title": "NFL 2022",
    "section": "",
    "text": "Provide both (1) a single ggplot and (2) a simple comment to describe the NFL weekly trend of weekly mean value of epa for each of the following two passers,\n\n‚ÄúJ.Allen‚Äù\n‚ÄúP.Mahomes‚Äù\n\n\n\ntwo_passers &lt;- c(\"J.Allen\", \"P.Mahomes\")\n\nfiltered_twopassers &lt;- NFL2022_stuffs_EPA %&gt;% \n  filter(passer %in% two_passers)\n\nmean_epa_data &lt;- filtered_twopassers %&gt;% group_by(week, passer) %&gt;% \n  summarise(mean_epa = mean(epa, na.rm = TRUE))\n\n`summarise()` has grouped output by 'week'. You can override using the\n`.groups` argument.\n\nggplot(mean_epa_data, aes(x= week, y= mean_epa, color = passer))+\n  geom_line()+\n  scale_color_manual(values =c(\"J.Allen\" =\"blue\", \"P.Mahomes\"=\"red\"))+\n  labs(x= \"Week\",\n       y= \"Mean value of expected points added (EPA)\")\n\n\n\n\n\n\n\n\nComment: Patrick Mahomes generally had a higher mean value of epa. However, there were a few weeks that Josh Allen had a higher mean value of epa."
  },
  {
    "objectID": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2f",
    "href": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2f",
    "title": "NFL 2022",
    "section": "",
    "text": "Calculate the difference between the mean value of epa for ‚ÄúJ.Allen‚Äù the mean value of epa for ‚ÄúP.Mahomes‚Äù for each value of week.\n\ndifference_epa &lt;- mean_epa_data %&gt;% \n  pivot_wider(names_from = passer, values_from = mean_epa)\n\ndifference_epa$epa_differnce &lt;- difference_epa$'J.Allen' - difference_epa$'P.Mahomes'\n\nprint(difference_epa)\n\n# A tibble: 22 √ó 4\n# Groups:   week [22]\n    week J.Allen P.Mahomes epa_differnce\n   &lt;int&gt;   &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1     1   0.530    0.698        -0.169 \n 2     2   0.487    0.148         0.339 \n 3     3   0.169    0.246        -0.0763\n 4     4   0.191    0.271        -0.0803\n 5     5   0.627    0.302         0.325 \n 6     6   0.307    0.133         0.173 \n 7     7  NA        0.701        NA     \n 8     8   0.224   NA            NA     \n 9     9  -0.208    0.0965       -0.304 \n10    10   0.161    0.589        -0.429 \n# ‚Ñπ 12 more rows"
  },
  {
    "objectID": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2g",
    "href": "posts/NFL in 2022/danl200-hw5-STARKEY_JAKE.html#q2g",
    "title": "NFL 2022",
    "section": "",
    "text": "Summarize the resulting data.frame in Q2d, with the following four variables:\n\nposteam: String abbreviation for the team with possession.\npasser: Name of the player who passed a ball to a receiver by initially taking a three-step drop, and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks.)\nmean_epa: Mean value of epa in 2022 for each passer\nn_pass: Number of observations for each passer\n\nThen find the top 10 NFL passers in 2022 in terms of the mean value of epa, conditioning that n_pass must be greater than or equal to the third quantile level of n_pass.\n\n\nsummary_data &lt;- NFL2022_stuffs_EPA %&gt;%\n  group_by(posteam, passer) %&gt;%\n  summarise(\n    mean_epa = mean(epa, na.rm = TRUE),\n    n_pass = n()\n  )\n\n`summarise()` has grouped output by 'posteam'. You can override using the\n`.groups` argument.\n\nquantile_threshold_passer &lt;- quantile(summary_data$n_pass, 0.75)\nfiltered_summary_data &lt;- summary_data %&gt;%\n  filter(n_pass &gt;= quantile_threshold_passer)\n\ntop_10_passers &lt;- filtered_summary_data %&gt;%\n  arrange(desc(mean_epa)) %&gt;% \n  head(n=10)\n  \ntop_10_passers\n\n# A tibble: 10 √ó 4\n# Groups:   posteam [10]\n   posteam passer       mean_epa n_pass\n   &lt;chr&gt;   &lt;chr&gt;           &lt;dbl&gt;  &lt;int&gt;\n 1 KC      P.Mahomes      0.286     880\n 2 MIA     T.Tagovailoa   0.234     453\n 3 SF      J.Garoppolo    0.200     348\n 4 BUF     J.Allen        0.172     785\n 5 DET     J.Goff         0.171     661\n 6 CIN     J.Burrow       0.153     854\n 7 DAL     D.Prescott     0.147     529\n 8 PHI     J.Hurts        0.138     672\n 9 JAX     T.Lawrence     0.128     764\n10 CLE     J.Brissett     0.0912    445"
  }
]